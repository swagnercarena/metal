{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from metal.mmtl.task import Task\n",
    "from metal.mmtl.scorer import Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deprecated\n",
    "# #########################\n",
    "# # Create Ines's model \n",
    "# #########################\n",
    "# import os \n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.functional as F\n",
    "# from tqdm import tqdm\n",
    "# from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "\n",
    "# from metal.mmtl.dataset import BERTDataset\n",
    "# from metal.end_model import EndModel\n",
    "\n",
    "# batch_size = 32\n",
    "# max_len = 200\n",
    "# weight_decay = 0.01\n",
    "# epochs = 1\n",
    "# lr = 0.001\n",
    "\n",
    "# model = 'bert-base-uncased' # also try bert-base-multilingual-cased (recommended)\n",
    "# src_path = os.path.join(os.environ['GLUEDATA'], 'QNLI/{}.tsv')\n",
    "# dataloaders = {}\n",
    "# for split in ['train', 'test', 'dev']: #, 'train', 'test']:\n",
    "#     label_idx = 3 if split in ['train', 'dev'] else -1\n",
    "#     dataset = BERTDataset(\n",
    "#         src_path.format(\"dev\"),\n",
    "#         sent1_idx=1,\n",
    "#         sent2_idx=2,\n",
    "#         label_idx=label_idx,\n",
    "#         skip_rows=400,\n",
    "#         label_fn=lambda label: 1 if label=='entailment' else 2 \n",
    "#     )\n",
    "#     dataloaders[split] = dataset.get_dataloader(max_len=max_len, batch_size=batch_size)\n",
    "    \n",
    "# class BertEncoder(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(BertEncoder, self).__init__()\n",
    "#         self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "#         for param in self.bert_model.parameters():\n",
    "#             param.requires_grad = False\n",
    "        \n",
    "#     def forward(self, data):\n",
    "#         tokens, segments, masks = data\n",
    "#         # TODO: check if we should return all layers or just last hidden representation \n",
    "#         _, hidden_layer = self.bert_model(input_ids=tokens, token_type_ids=segments, attention_mask=masks)\n",
    "#         return hidden_layer\n",
    "    \n",
    "# encoder_module = BertEncoder()\n",
    "# end_model = EndModel(\n",
    "#     [768, 2],  # TODO: remove bias\n",
    "#     input_module=encoder_module,\n",
    "#     seed=123,\n",
    "#     skip_head=False,\n",
    "#     input_relu=False,\n",
    "#     input_batchnorm=False,\n",
    "#     verbose=False,\n",
    "#     device=torch.device('cuda'),\n",
    "# )\n",
    "\n",
    "# end_model.train_model(\n",
    "#     train_data=dataloaders['dev'],\n",
    "#     valid_data=dataloaders['dev'],\n",
    "#     l2=weight_decay,\n",
    "#     lr=lr,\n",
    "#     n_epochs=epochs,\n",
    "#     verbose=True,\n",
    "#     checkpoint=False,\n",
    "#     log_unit='epochs', \n",
    "#     log_train_every=1,\n",
    "#     log_valid_every=1,\n",
    "#     progress_bar=True,\n",
    "# )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deprecated\n",
    "# # Test \n",
    "# def custom_eval_function(Y, Y_pred, probs=None):\n",
    "#     print(\"Running custom_eval_function\")\n",
    "#     return {\"custom_metric\" : 0}\n",
    "\n",
    "# # Create a scorer (standard_metrics are broken)\n",
    "# dummy_scorer = Scorer(standard_metrics=[], custom_metric_fns=[custom_eval_function])\n",
    "\n",
    "# # Create task with scorer\n",
    "# data_loaders = [dataloaders[x] for x in [\"train\", \"test\", \"dev\"]]\n",
    "# foo_task = Task(name=\"foo_task\", \n",
    "#                 input_module=encoder_module,\n",
    "#                 head_module=end_model,\n",
    "#                 data_loaders=data_loaders, scorers=[scorer])\n",
    "\n",
    "# # Call scorer on model / task / etc\n",
    "# dummy_scorer(foo_task, end_model, data_loaders[-1], split_name=\"test_scorer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deprecated\n",
    "# # Test standard loss function\n",
    "\n",
    "# # Create a scorer (standard_metrics are broken)\n",
    "# dummy_loss_scorer = Scorer(standard_metrics=[\"f1\"])\n",
    "\n",
    "# # Create task with scorer\n",
    "# data_loaders = [dataloaders[x] for x in [\"train\", \"test\", \"dev\"]]\n",
    "# foo_task = Task(name=\"foo_task\", \n",
    "#                 input_module=encoder_module,\n",
    "#                 head_module=end_model,\n",
    "#                 data_loaders=data_loaders, scorers=[dummy_loss_scorer])\n",
    "\n",
    "# # Call scorer on model / task / etc\n",
    "# dummy_loss_scorer(foo_task, end_model, data_loaders[-1], split_name=\"test_scorer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test head_output optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Network architecture:\n",
      "MetalModel(\n",
      "  (input_modules): ModuleDict(\n",
      "    (bar_task): Linear(in_features=2, out_features=10, bias=True)\n",
      "    (foo_task): Linear(in_features=2, out_features=10, bias=True)\n",
      "  )\n",
      "  (head_modules): ModuleDict(\n",
      "    (bar_task): Linear(in_features=10, out_features=2, bias=True)\n",
      "    (foo_task): Linear(in_features=10, out_features=2, bias=True)\n",
      "  )\n",
      "  (task_paths): ModuleDict(\n",
      "    (bar_task): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=10, bias=True)\n",
      "      (1): Linear(in_features=10, out_features=2, bias=True)\n",
      "    )\n",
      "    (foo_task): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=10, bias=True)\n",
      "      (1): Linear(in_features=10, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "Batch 0 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <generator object tqdm_notebook.__iter__ at 0x7f0dbd2ea570>\n",
      "Traceback (most recent call last):\n",
      "  File \"/dfs/scratch0/vschen/venv-mmtl/lib/python3.6/site-packages/tqdm/_tqdm_notebook.py\", line 226, in __iter__\n",
      "    self.sp(bar_style='danger')\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'sp'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-1e020da82bd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMetalModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultitaskTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/lfs/1/maxlam/metal/metal/mmtl/trainer.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, tasks, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0mvalid_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_to_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mVALID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m                 )\n\u001b[1;32m    199\u001b[0m                 \u001b[0;31m# metrics_hist.update(metrics_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/1/maxlam/metal/metal/mmtl/trainer.py\u001b[0m in \u001b[0;36m_execute_logging\u001b[0;34m(self, model, task_name, train_loader, valid_loader, loss, batch_size)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_to_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mscorer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                 \u001b[0mmetrics_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/1/maxlam/metal/metal/mmtl/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, task, model, dataloader, split_name, head_output)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# Place data on gpu if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0mXb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplace_on_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'device'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def make_dataloader(n):\n",
    "    X = np.random.random((n, 2)) * 2 - 1\n",
    "    Y = (X[:, 0] > X[:, 1] + 0.25).astype(int) + 1\n",
    "\n",
    "    X = torch.tensor(X, dtype=torch.float)\n",
    "    Y = torch.tensor(Y, dtype=torch.long)\n",
    "\n",
    "    div1 = int(n*0.8)\n",
    "    div2 = int(n*0.9)\n",
    "    Xs = [X[:div1], X[div1:div2], X[div2:]]\n",
    "    Ys = [Y[:div1], Y[div1:div2], Y[div2:]]\n",
    "\n",
    "    dataset = TensorDataset(Xs[0], Ys[0])\n",
    "    data_loader = DataLoader(dataset, batch_size=4)\n",
    "    return data_loader\n",
    "\n",
    "import torch.nn as nn\n",
    "from metal.mmtl.task import Task\n",
    "\n",
    "foo_input = nn.Linear(2, 10)\n",
    "bar_input = foo_input #nn.Linear(100, 7)\n",
    "\n",
    "foo_head = nn.Linear(10, 2)\n",
    "bar_head = nn.Linear(10, 2)\n",
    "\n",
    "scorer = Scorer()\n",
    "foo = Task(\"foo_task\", [make_dataloader(5000), make_dataloader(500), make_dataloader(500)], foo_input, foo_head, scorers=[scorer])\n",
    "bar = Task(\"bar_task\", [make_dataloader(2000), make_dataloader(500), make_dataloader(500)], bar_input, bar_head, scorers=[scorer])\n",
    "tasks = [foo, bar]\n",
    "\n",
    "from metal.end_model import EndModel\n",
    "from metal.mmtl.metal_model import MetalModel\n",
    "from metal.mmtl.trainer import MultitaskTrainer\n",
    "\n",
    "model = MetalModel(tasks)\n",
    "trainer = MultitaskTrainer()\n",
    "trainer.train_model(model, tasks, n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
