{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal.mmtl.trainer import MultitaskTrainer\n",
    "from metal.mmtl.glue.glue_tasks import create_glue_tasks_payloads\n",
    "from metal.mmtl.metal_model import MetalModel\n",
    "from metal.mmtl.slicing.slice_model import SliceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize normal payloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_kwargs = {\n",
    "    \"dl_kwargs\": {\"batch_size\": 8},\n",
    "    \"freeze_bert\":False,\n",
    "    \"bert_model\": 'bert-base-cased',\n",
    "    \"max_len\": 200,\n",
    "    \"attention\": False\n",
    "}\n",
    "task_names = [\"RTE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using random seed: 107448\n",
      "Loading RTE Dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7d963e04164b488db6d4b40ea4afc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2490), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5237ec4c164c9f98bddcc3735de106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=277), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69da8d6ad3e242b9bc7055bf8fcaacd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 13.4 s, sys: 1.07 s, total: 14.5 s\n",
      "Wall time: 15.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create tasks and payloads\n",
    "tasks, payloads = create_glue_tasks_payloads(task_names, **task_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([ClassificationTask(name=RTE, loss_multiplier=1.00)],\n",
       " [Payload(RTE_train: labels_to_tasks=[{'RTE_gold': 'RTE'}], split=train),\n",
       "  Payload(RTE_valid: labels_to_tasks=[{'RTE_gold': 'RTE'}], split=valid),\n",
       "  Payload(RTE_test: labels_to_tasks=[{'RTE_gold': 'RTE'}], split=test)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks, payloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize slice payloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using random seed: 709265\n",
      "Loading RTE Dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8582efefbfd4fc0acdc1a691346764b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2490), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b185253e0fda4d1093f6197e58162e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=277), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97320bc5f1644da1b1f7bd1ffd25ba17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Added label_set with 1003/2490 labels for task RTE_slice:dash_semicolon to payload RTE_train.\n",
      "Added label_set with 64/2490 labels for task RTE_slice:more_people to payload RTE_train.\n",
      "Added label_set with 2490/2490 labels for task RTE_slice:BASE to payload RTE_train.\n",
      "Added label_set with 116/277 labels for task RTE_slice:dash_semicolon to payload RTE_valid.\n",
      "Added label_set with 12/277 labels for task RTE_slice:more_people to payload RTE_valid.\n",
      "Added label_set with 277/277 labels for task RTE_slice:BASE to payload RTE_valid.\n",
      "Added label_set with 1103/3000 labels for task RTE_slice:dash_semicolon to payload RTE_test.\n",
      "Added label_set with 67/3000 labels for task RTE_slice:more_people to payload RTE_test.\n",
      "Added label_set with 3000/3000 labels for task RTE_slice:BASE to payload RTE_test.\n"
     ]
    }
   ],
   "source": [
    "# Create tasks and payloads\n",
    "task_kwargs.update({\"slice_dict\": {\n",
    "    \"RTE\": [\"dash_semicolon\", \"more_people\", \"BASE\"]}\n",
    "})\n",
    "task_kwargs['attention'] = None\n",
    "\n",
    "tasks_slice, payloads_slice = create_glue_tasks_payloads(\n",
    "    task_names, **task_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([ClassificationTask(name=RTE, loss_multiplier=1.00),\n",
       "  ClassificationTask(name=RTE_slice:dash_semicolon, loss_multiplier=1.00),\n",
       "  ClassificationTask(name=RTE_slice:more_people, loss_multiplier=1.00),\n",
       "  ClassificationTask(name=RTE_slice:BASE, loss_multiplier=1.00)],\n",
       " [Payload(RTE_train: labels_to_tasks=[{'RTE_gold': 'RTE', 'RTE_slice:dash_semicolon': 'RTE_slice:dash_semicolon', 'RTE_slice:more_people': 'RTE_slice:more_people', 'RTE_slice:BASE': 'RTE_slice:BASE'}], split=train),\n",
       "  Payload(RTE_valid: labels_to_tasks=[{'RTE_gold': 'RTE', 'RTE_slice:dash_semicolon': 'RTE_slice:dash_semicolon', 'RTE_slice:more_people': 'RTE_slice:more_people', 'RTE_slice:BASE': 'RTE_slice:BASE'}], split=valid),\n",
       "  Payload(RTE_test: labels_to_tasks=[{'RTE_gold': 'RTE', 'RTE_slice:dash_semicolon': 'RTE_slice:dash_semicolon', 'RTE_slice:more_people': 'RTE_slice:more_people', 'RTE_slice:BASE': 'RTE_slice:BASE'}], split=test)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks_slice, payloads_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and train baseline model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MetalModel(tasks, seed=SEED, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning train loop.\n",
      "Expecting a total of approximately 2496 examples and 312 batches per epoch from 1 payload(s) in the train split.\n",
      "Writing config to /dfs/scratch0/vschen/metal-mmtl/logs/2019_04_15/21_38_47/config.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5398ee6e7840129988fe8b4c3bf820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10 epo]: RTE:[RTE_train/RTE_gold/loss=6.88e-01, RTE_valid/RTE_gold/accuracy=5.38e-01] model:[train/all/loss=6.88e-01, train/all/lr=5.00e-05]\n",
      "Saving model at iteration 0.10 with best (max) score RTE/RTE_valid/RTE_gold/accuracy=0.538\n",
      "[0.21 epo]: RTE:[RTE_train/RTE_gold/loss=7.16e-01, RTE_valid/RTE_gold/accuracy=4.73e-01] model:[train/all/loss=7.16e-01, train/all/lr=5.00e-05]\n",
      "[0.31 epo]: RTE:[RTE_train/RTE_gold/loss=6.82e-01, RTE_valid/RTE_gold/accuracy=5.52e-01] model:[train/all/loss=6.82e-01, train/all/lr=5.00e-05]\n",
      "Saving model at iteration 0.31 with best (max) score RTE/RTE_valid/RTE_gold/accuracy=0.552\n",
      "[0.41 epo]: RTE:[RTE_train/RTE_gold/loss=6.86e-01, RTE_valid/RTE_gold/accuracy=5.70e-01] model:[train/all/loss=6.86e-01, train/all/lr=5.00e-05]\n",
      "Saving model at iteration 0.41 with best (max) score RTE/RTE_valid/RTE_gold/accuracy=0.570\n",
      "[0.51 epo]: RTE:[RTE_train/RTE_gold/loss=6.71e-01, RTE_valid/RTE_gold/accuracy=5.88e-01] model:[train/all/loss=6.71e-01, train/all/lr=5.00e-05]\n",
      "Saving model at iteration 0.51 with best (max) score RTE/RTE_valid/RTE_gold/accuracy=0.588\n",
      "[0.62 epo]: RTE:[RTE_train/RTE_gold/loss=6.64e-01, RTE_valid/RTE_gold/accuracy=5.74e-01] model:[train/all/loss=6.64e-01, train/all/lr=5.00e-05]\n",
      "[0.72 epo]: RTE:[RTE_train/RTE_gold/loss=6.69e-01, RTE_valid/RTE_gold/accuracy=5.88e-01] model:[train/all/loss=6.69e-01, train/all/lr=5.00e-05]\n",
      "[0.82 epo]: RTE:[RTE_train/RTE_gold/loss=6.69e-01, RTE_valid/RTE_gold/accuracy=6.10e-01] model:[train/all/loss=6.69e-01, train/all/lr=5.00e-05]\n",
      "Saving model at iteration 0.82 with best (max) score RTE/RTE_valid/RTE_gold/accuracy=0.610\n",
      "[0.92 epo]: RTE:[RTE_train/RTE_gold/loss=6.32e-01, RTE_valid/RTE_gold/accuracy=6.43e-01] model:[train/all/loss=6.32e-01, train/all/lr=5.00e-05]\n",
      "Saving model at iteration 0.92 with best (max) score RTE/RTE_valid/RTE_gold/accuracy=0.643\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d60f4a7e823546e1abd843fbf474d288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.03 epo]: RTE:[RTE_train/RTE_gold/loss=6.25e-01, RTE_valid/RTE_gold/accuracy=6.75e-01] model:[train/all/loss=6.25e-01, train/all/lr=5.00e-05]\n",
      "Saving model at iteration 1.03 with best (max) score RTE/RTE_valid/RTE_gold/accuracy=0.675\n",
      "[1.13 epo]: RTE:[RTE_train/RTE_gold/loss=5.73e-01, RTE_valid/RTE_gold/accuracy=6.61e-01] model:[train/all/loss=5.73e-01, train/all/lr=5.00e-05]\n",
      "[1.23 epo]: RTE:[RTE_train/RTE_gold/loss=5.73e-01, RTE_valid/RTE_gold/accuracy=6.43e-01] model:[train/all/loss=5.73e-01, train/all/lr=5.00e-05]\n",
      "[1.33 epo]: RTE:[RTE_train/RTE_gold/loss=5.94e-01, RTE_valid/RTE_gold/accuracy=6.28e-01] model:[train/all/loss=5.94e-01, train/all/lr=5.00e-05]\n",
      "[1.44 epo]: RTE:[RTE_train/RTE_gold/loss=5.76e-01, RTE_valid/RTE_gold/accuracy=6.71e-01] model:[train/all/loss=5.76e-01, train/all/lr=5.00e-05]\n",
      "[1.54 epo]: RTE:[RTE_train/RTE_gold/loss=5.68e-01, RTE_valid/RTE_gold/accuracy=6.46e-01] model:[train/all/loss=5.68e-01, train/all/lr=5.00e-05]\n",
      "[1.64 epo]: RTE:[RTE_train/RTE_gold/loss=5.51e-01, RTE_valid/RTE_gold/accuracy=6.75e-01] model:[train/all/loss=5.51e-01, train/all/lr=5.00e-05]\n",
      "[1.74 epo]: RTE:[RTE_train/RTE_gold/loss=5.47e-01, RTE_valid/RTE_gold/accuracy=6.79e-01] model:[train/all/loss=5.47e-01, train/all/lr=5.00e-05]\n",
      "Saving model at iteration 1.74 with best (max) score RTE/RTE_valid/RTE_gold/accuracy=0.679\n",
      "[1.85 epo]: RTE:[RTE_train/RTE_gold/loss=5.60e-01, RTE_valid/RTE_gold/accuracy=6.35e-01] model:[train/all/loss=5.60e-01, train/all/lr=5.00e-05]\n",
      "[1.95 epo]: RTE:[RTE_train/RTE_gold/loss=5.87e-01, RTE_valid/RTE_gold/accuracy=6.35e-01] model:[train/all/loss=5.87e-01, train/all/lr=5.00e-05]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b6f82b032e45f588743b3cf70dacb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.05 epo]: RTE:[RTE_train/RTE_gold/loss=5.46e-01, RTE_valid/RTE_gold/accuracy=6.53e-01] model:[train/all/loss=5.46e-01, train/all/lr=5.00e-05]\n",
      "[2.15 epo]: RTE:[RTE_train/RTE_gold/loss=4.09e-01, RTE_valid/RTE_gold/accuracy=6.82e-01] model:[train/all/loss=4.09e-01, train/all/lr=5.00e-05]\n",
      "Saving model at iteration 2.15 with best (max) score RTE/RTE_valid/RTE_gold/accuracy=0.682\n",
      "[2.26 epo]: RTE:[RTE_train/RTE_gold/loss=3.71e-01, RTE_valid/RTE_gold/accuracy=6.68e-01] model:[train/all/loss=3.71e-01, train/all/lr=5.00e-05]\n",
      "[2.36 epo]: RTE:[RTE_train/RTE_gold/loss=4.73e-01, RTE_valid/RTE_gold/accuracy=6.97e-01] model:[train/all/loss=4.73e-01, train/all/lr=5.00e-05]\n",
      "Saving model at iteration 2.36 with best (max) score RTE/RTE_valid/RTE_gold/accuracy=0.697\n",
      "[2.46 epo]: RTE:[RTE_train/RTE_gold/loss=4.82e-01, RTE_valid/RTE_gold/accuracy=6.68e-01] model:[train/all/loss=4.82e-01, train/all/lr=5.00e-05]\n",
      "[2.56 epo]: RTE:[RTE_train/RTE_gold/loss=4.55e-01, RTE_valid/RTE_gold/accuracy=6.68e-01] model:[train/all/loss=4.55e-01, train/all/lr=5.00e-05]\n",
      "[2.67 epo]: RTE:[RTE_train/RTE_gold/loss=5.09e-01, RTE_valid/RTE_gold/accuracy=6.53e-01] model:[train/all/loss=5.09e-01, train/all/lr=5.00e-05]\n",
      "[2.77 epo]: RTE:[RTE_train/RTE_gold/loss=4.11e-01, RTE_valid/RTE_gold/accuracy=7.04e-01] model:[train/all/loss=4.11e-01, train/all/lr=5.00e-05]\n",
      "Saving model at iteration 2.77 with best (max) score RTE/RTE_valid/RTE_gold/accuracy=0.704\n",
      "[2.87 epo]: RTE:[RTE_train/RTE_gold/loss=5.26e-01, RTE_valid/RTE_gold/accuracy=6.57e-01] model:[train/all/loss=5.26e-01, train/all/lr=5.00e-05]\n",
      "[2.97 epo]: RTE:[RTE_train/RTE_gold/loss=4.93e-01, RTE_valid/RTE_gold/accuracy=6.93e-01] model:[train/all/loss=4.93e-01, train/all/lr=5.00e-05]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4effcbc139504b369243b362df9dbf7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.08 epo]: RTE:[RTE_train/RTE_gold/loss=3.17e-01, RTE_valid/RTE_gold/accuracy=6.86e-01] model:[train/all/loss=3.17e-01, train/all/lr=5.00e-05]\n",
      "[3.18 epo]: RTE:[RTE_train/RTE_gold/loss=2.95e-01, RTE_valid/RTE_gold/accuracy=6.61e-01] model:[train/all/loss=2.95e-01, train/all/lr=5.00e-05]\n",
      "[3.28 epo]: RTE:[RTE_train/RTE_gold/loss=4.13e-01, RTE_valid/RTE_gold/accuracy=6.64e-01] model:[train/all/loss=4.13e-01, train/all/lr=5.00e-05]\n",
      "[3.38 epo]: RTE:[RTE_train/RTE_gold/loss=3.21e-01, RTE_valid/RTE_gold/accuracy=6.82e-01] model:[train/all/loss=3.21e-01, train/all/lr=5.00e-05]\n",
      "[3.49 epo]: RTE:[RTE_train/RTE_gold/loss=2.72e-01, RTE_valid/RTE_gold/accuracy=6.71e-01] model:[train/all/loss=2.72e-01, train/all/lr=5.00e-05]\n",
      "[3.59 epo]: RTE:[RTE_train/RTE_gold/loss=4.57e-01, RTE_valid/RTE_gold/accuracy=6.43e-01] model:[train/all/loss=4.57e-01, train/all/lr=5.00e-05]\n",
      "[3.69 epo]: RTE:[RTE_train/RTE_gold/loss=3.86e-01, RTE_valid/RTE_gold/accuracy=6.71e-01] model:[train/all/loss=3.86e-01, train/all/lr=5.00e-05]\n",
      "[3.79 epo]: RTE:[RTE_train/RTE_gold/loss=4.45e-01, RTE_valid/RTE_gold/accuracy=6.61e-01] model:[train/all/loss=4.45e-01, train/all/lr=5.00e-05]\n",
      "[3.90 epo]: RTE:[RTE_train/RTE_gold/loss=3.36e-01, RTE_valid/RTE_gold/accuracy=6.64e-01] model:[train/all/loss=3.36e-01, train/all/lr=5.00e-05]\n",
      "[4.0 epo]: RTE:[RTE_train/RTE_gold/loss=4.49e-01, RTE_valid/RTE_gold/accuracy=6.93e-01] model:[train/all/loss=4.49e-01, train/all/lr=5.00e-05]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8dfd25be7684be18a0c94a9150f1b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.10 epo]: RTE:[RTE_train/RTE_gold/loss=2.73e-01, RTE_valid/RTE_gold/accuracy=6.71e-01] model:[train/all/loss=2.73e-01, train/all/lr=5.00e-05]\n",
      "[4.21 epo]: RTE:[RTE_train/RTE_gold/loss=2.95e-01, RTE_valid/RTE_gold/accuracy=6.79e-01] model:[train/all/loss=2.95e-01, train/all/lr=5.00e-05]\n",
      "[4.31 epo]: RTE:[RTE_train/RTE_gold/loss=3.41e-01, RTE_valid/RTE_gold/accuracy=6.53e-01] model:[train/all/loss=3.41e-01, train/all/lr=5.00e-05]\n",
      "[4.41 epo]: RTE:[RTE_train/RTE_gold/loss=3.56e-01, RTE_valid/RTE_gold/accuracy=6.64e-01] model:[train/all/loss=3.56e-01, train/all/lr=5.00e-05]\n",
      "[4.51 epo]: RTE:[RTE_train/RTE_gold/loss=3.45e-01, RTE_valid/RTE_gold/accuracy=6.97e-01] model:[train/all/loss=3.45e-01, train/all/lr=5.00e-05]\n",
      "[4.62 epo]: RTE:[RTE_train/RTE_gold/loss=2.78e-01, RTE_valid/RTE_gold/accuracy=7.00e-01] model:[train/all/loss=2.78e-01, train/all/lr=5.00e-05]\n",
      "[4.72 epo]: RTE:[RTE_train/RTE_gold/loss=3.52e-01, RTE_valid/RTE_gold/accuracy=6.75e-01] model:[train/all/loss=3.52e-01, train/all/lr=5.00e-05]\n",
      "[4.82 epo]: RTE:[RTE_train/RTE_gold/loss=3.45e-01, RTE_valid/RTE_gold/accuracy=6.53e-01] model:[train/all/loss=3.45e-01, train/all/lr=5.00e-05]\n",
      "[4.92 epo]: RTE:[RTE_train/RTE_gold/loss=4.82e-01, RTE_valid/RTE_gold/accuracy=6.53e-01] model:[train/all/loss=4.82e-01, train/all/lr=5.00e-05]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6556ad2aedfe4f7d96e58d38bb3238f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.03 epo]: RTE:[RTE_train/RTE_gold/loss=3.52e-01, RTE_valid/RTE_gold/accuracy=6.75e-01] model:[train/all/loss=3.52e-01, train/all/lr=5.00e-05]\n",
      "[5.13 epo]: RTE:[RTE_train/RTE_gold/loss=2.02e-01, RTE_valid/RTE_gold/accuracy=6.68e-01] model:[train/all/loss=2.02e-01, train/all/lr=5.00e-05]\n",
      "[5.23 epo]: RTE:[RTE_train/RTE_gold/loss=2.96e-01, RTE_valid/RTE_gold/accuracy=6.43e-01] model:[train/all/loss=2.96e-01, train/all/lr=5.00e-05]\n",
      "[5.33 epo]: RTE:[RTE_train/RTE_gold/loss=4.26e-01, RTE_valid/RTE_gold/accuracy=6.86e-01] model:[train/all/loss=4.26e-01, train/all/lr=5.00e-05]\n",
      "[5.44 epo]: RTE:[RTE_train/RTE_gold/loss=2.31e-01, RTE_valid/RTE_gold/accuracy=6.82e-01] model:[train/all/loss=2.31e-01, train/all/lr=5.00e-05]\n",
      "[5.54 epo]: RTE:[RTE_train/RTE_gold/loss=3.65e-01, RTE_valid/RTE_gold/accuracy=6.57e-01] model:[train/all/loss=3.65e-01, train/all/lr=5.00e-05]\n",
      "[5.64 epo]: RTE:[RTE_train/RTE_gold/loss=3.11e-01, RTE_valid/RTE_gold/accuracy=6.64e-01] model:[train/all/loss=3.11e-01, train/all/lr=5.00e-05]\n",
      "[5.74 epo]: RTE:[RTE_train/RTE_gold/loss=4.58e-01, RTE_valid/RTE_gold/accuracy=6.82e-01] model:[train/all/loss=4.58e-01, train/all/lr=5.00e-05]\n",
      "[5.85 epo]: RTE:[RTE_train/RTE_gold/loss=4.41e-01, RTE_valid/RTE_gold/accuracy=6.86e-01] model:[train/all/loss=4.41e-01, train/all/lr=5.00e-05]\n",
      "[5.95 epo]: RTE:[RTE_train/RTE_gold/loss=3.04e-01, RTE_valid/RTE_gold/accuracy=6.68e-01] model:[train/all/loss=3.04e-01, train/all/lr=5.00e-05]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87da68b1c71434dbef0c64709cbd090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.05 epo]: RTE:[RTE_train/RTE_gold/loss=1.63e-01, RTE_valid/RTE_gold/accuracy=6.86e-01] model:[train/all/loss=1.63e-01, train/all/lr=5.00e-05]\n",
      "[6.15 epo]: RTE:[RTE_train/RTE_gold/loss=2.66e-01, RTE_valid/RTE_gold/accuracy=6.90e-01] model:[train/all/loss=2.66e-01, train/all/lr=5.00e-05]\n",
      "[6.26 epo]: RTE:[RTE_train/RTE_gold/loss=2.57e-01, RTE_valid/RTE_gold/accuracy=6.64e-01] model:[train/all/loss=2.57e-01, train/all/lr=5.00e-05]\n",
      "[6.36 epo]: RTE:[RTE_train/RTE_gold/loss=2.58e-01, RTE_valid/RTE_gold/accuracy=6.46e-01] model:[train/all/loss=2.58e-01, train/all/lr=5.00e-05]\n",
      "[6.46 epo]: RTE:[RTE_train/RTE_gold/loss=3.55e-01, RTE_valid/RTE_gold/accuracy=6.57e-01] model:[train/all/loss=3.55e-01, train/all/lr=5.00e-05]\n",
      "[6.56 epo]: RTE:[RTE_train/RTE_gold/loss=3.78e-01, RTE_valid/RTE_gold/accuracy=6.35e-01] model:[train/all/loss=3.78e-01, train/all/lr=5.00e-05]\n",
      "[6.67 epo]: RTE:[RTE_train/RTE_gold/loss=4.28e-01, RTE_valid/RTE_gold/accuracy=6.28e-01] model:[train/all/loss=4.28e-01, train/all/lr=5.00e-05]\n",
      "[6.77 epo]: RTE:[RTE_train/RTE_gold/loss=3.68e-01, RTE_valid/RTE_gold/accuracy=6.50e-01] model:[train/all/loss=3.68e-01, train/all/lr=5.00e-05]\n",
      "[6.87 epo]: RTE:[RTE_train/RTE_gold/loss=2.73e-01, RTE_valid/RTE_gold/accuracy=6.43e-01] model:[train/all/loss=2.73e-01, train/all/lr=5.00e-05]\n",
      "[6.97 epo]: RTE:[RTE_train/RTE_gold/loss=3.68e-01, RTE_valid/RTE_gold/accuracy=6.68e-01] model:[train/all/loss=3.68e-01, train/all/lr=5.00e-05]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df41b228b0b4449a57663b6977282e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.08 epo]: RTE:[RTE_train/RTE_gold/loss=2.05e-01, RTE_valid/RTE_gold/accuracy=6.68e-01] model:[train/all/loss=2.05e-01, train/all/lr=5.00e-05]\n",
      "[7.18 epo]: RTE:[RTE_train/RTE_gold/loss=3.03e-01, RTE_valid/RTE_gold/accuracy=6.75e-01] model:[train/all/loss=3.03e-01, train/all/lr=5.00e-05]\n",
      "[7.28 epo]: RTE:[RTE_train/RTE_gold/loss=3.56e-01, RTE_valid/RTE_gold/accuracy=6.75e-01] model:[train/all/loss=3.56e-01, train/all/lr=5.00e-05]\n",
      "[7.38 epo]: RTE:[RTE_train/RTE_gold/loss=3.37e-01, RTE_valid/RTE_gold/accuracy=6.79e-01] model:[train/all/loss=3.37e-01, train/all/lr=5.00e-05]\n",
      "[7.49 epo]: RTE:[RTE_train/RTE_gold/loss=3.98e-01, RTE_valid/RTE_gold/accuracy=6.79e-01] model:[train/all/loss=3.98e-01, train/all/lr=5.00e-05]\n",
      "[7.59 epo]: RTE:[RTE_train/RTE_gold/loss=4.29e-01, RTE_valid/RTE_gold/accuracy=6.82e-01] model:[train/all/loss=4.29e-01, train/all/lr=5.00e-05]\n",
      "[7.69 epo]: RTE:[RTE_train/RTE_gold/loss=2.43e-01, RTE_valid/RTE_gold/accuracy=6.53e-01] model:[train/all/loss=2.43e-01, train/all/lr=5.00e-05]\n",
      "[7.79 epo]: RTE:[RTE_train/RTE_gold/loss=3.65e-01, RTE_valid/RTE_gold/accuracy=6.21e-01] model:[train/all/loss=3.65e-01, train/all/lr=5.00e-05]\n",
      "[7.90 epo]: RTE:[RTE_train/RTE_gold/loss=2.82e-01, RTE_valid/RTE_gold/accuracy=6.21e-01] model:[train/all/loss=2.82e-01, train/all/lr=5.00e-05]\n",
      "[8.0 epo]: RTE:[RTE_train/RTE_gold/loss=4.19e-01, RTE_valid/RTE_gold/accuracy=6.17e-01] model:[train/all/loss=4.19e-01, train/all/lr=5.00e-05]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e44cb16a8834fd5aca38d8bc77e72e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.10 epo]: RTE:[RTE_train/RTE_gold/loss=2.16e-01, RTE_valid/RTE_gold/accuracy=6.32e-01] model:[train/all/loss=2.16e-01, train/all/lr=5.00e-05]\n",
      "[8.21 epo]: RTE:[RTE_train/RTE_gold/loss=2.79e-01, RTE_valid/RTE_gold/accuracy=6.39e-01] model:[train/all/loss=2.79e-01, train/all/lr=5.00e-05]\n",
      "[8.31 epo]: RTE:[RTE_train/RTE_gold/loss=3.04e-01, RTE_valid/RTE_gold/accuracy=6.53e-01] model:[train/all/loss=3.04e-01, train/all/lr=5.00e-05]\n",
      "[8.41 epo]: RTE:[RTE_train/RTE_gold/loss=3.81e-01, RTE_valid/RTE_gold/accuracy=5.96e-01] model:[train/all/loss=3.81e-01, train/all/lr=5.00e-05]\n",
      "[8.51 epo]: RTE:[RTE_train/RTE_gold/loss=3.00e-01, RTE_valid/RTE_gold/accuracy=6.43e-01] model:[train/all/loss=3.00e-01, train/all/lr=5.00e-05]\n",
      "[8.62 epo]: RTE:[RTE_train/RTE_gold/loss=4.18e-01, RTE_valid/RTE_gold/accuracy=6.39e-01] model:[train/all/loss=4.18e-01, train/all/lr=5.00e-05]\n",
      "[8.72 epo]: RTE:[RTE_train/RTE_gold/loss=3.83e-01, RTE_valid/RTE_gold/accuracy=6.17e-01] model:[train/all/loss=3.83e-01, train/all/lr=5.00e-05]\n",
      "[8.82 epo]: RTE:[RTE_train/RTE_gold/loss=3.01e-01, RTE_valid/RTE_gold/accuracy=6.25e-01] model:[train/all/loss=3.01e-01, train/all/lr=5.00e-05]\n",
      "[8.92 epo]: RTE:[RTE_train/RTE_gold/loss=4.59e-01, RTE_valid/RTE_gold/accuracy=6.06e-01] model:[train/all/loss=4.59e-01, train/all/lr=5.00e-05]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae8f6f301cf412e9d250b3b8aa7c5f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.03 epo]: RTE:[RTE_train/RTE_gold/loss=3.81e-01, RTE_valid/RTE_gold/accuracy=6.43e-01] model:[train/all/loss=3.81e-01, train/all/lr=5.00e-05]\n",
      "[9.13 epo]: RTE:[RTE_train/RTE_gold/loss=2.13e-01, RTE_valid/RTE_gold/accuracy=6.25e-01] model:[train/all/loss=2.13e-01, train/all/lr=5.00e-05]\n",
      "[9.23 epo]: RTE:[RTE_train/RTE_gold/loss=2.79e-01, RTE_valid/RTE_gold/accuracy=6.32e-01] model:[train/all/loss=2.79e-01, train/all/lr=5.00e-05]\n",
      "[9.33 epo]: RTE:[RTE_train/RTE_gold/loss=3.56e-01, RTE_valid/RTE_gold/accuracy=6.14e-01] model:[train/all/loss=3.56e-01, train/all/lr=5.00e-05]\n",
      "[9.44 epo]: RTE:[RTE_train/RTE_gold/loss=3.90e-01, RTE_valid/RTE_gold/accuracy=6.28e-01] model:[train/all/loss=3.90e-01, train/all/lr=5.00e-05]\n",
      "[9.54 epo]: RTE:[RTE_train/RTE_gold/loss=2.69e-01, RTE_valid/RTE_gold/accuracy=6.61e-01] model:[train/all/loss=2.69e-01, train/all/lr=5.00e-05]\n",
      "[9.64 epo]: RTE:[RTE_train/RTE_gold/loss=3.93e-01, RTE_valid/RTE_gold/accuracy=5.85e-01] model:[train/all/loss=3.93e-01, train/all/lr=5.00e-05]\n",
      "[9.74 epo]: RTE:[RTE_train/RTE_gold/loss=3.66e-01, RTE_valid/RTE_gold/accuracy=6.17e-01] model:[train/all/loss=3.66e-01, train/all/lr=5.00e-05]\n",
      "[9.85 epo]: RTE:[RTE_train/RTE_gold/loss=3.02e-01, RTE_valid/RTE_gold/accuracy=5.78e-01] model:[train/all/loss=3.02e-01, train/all/lr=5.00e-05]\n",
      "[9.95 epo]: RTE:[RTE_train/RTE_gold/loss=4.30e-01, RTE_valid/RTE_gold/accuracy=6.43e-01] model:[train/all/loss=4.30e-01, train/all/lr=5.00e-05]\n",
      "\n",
      "[10.00 epo]: RTE:[RTE_train/RTE_gold/loss=4.70e-01, RTE_valid/RTE_gold/accuracy=6.28e-01] model:[train/all/loss=4.70e-01, train/all/lr=5.00e-05]\n",
      "Restoring best model from iteration 2.77 with score 0.704\n",
      "Finished training\n",
      "{'RTE/RTE_test/RTE_gold/accuracy': 0.0,\n",
      " 'RTE/RTE_train/RTE_gold/accuracy': 0.9020080321285141,\n",
      " 'RTE/RTE_valid/RTE_gold/accuracy': 0.703971119133574}\n",
      "Writing metrics to /dfs/scratch0/vschen/metal-mmtl/logs/2019_04_15/21_38_47/metrics.json\n",
      "Writing log to /dfs/scratch0/vschen/metal-mmtl/logs/2019_04_15/21_38_47/log.json\n",
      "Full model saved at /dfs/scratch0/vschen/metal-mmtl/logs/2019_04_15/21_38_47/model.pkl\n",
      "CPU times: user 14min 19s, sys: 1min 23s, total: 15min 42s\n",
      "Wall time: 16min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer = MultitaskTrainer(seed=SEED)\n",
    "trainer.train_model(\n",
    "    model,\n",
    "    payloads,\n",
    "    checkpoint_metric=\"RTE/RTE_valid/RTE_gold/accuracy\",\n",
    "    checkpoint_metric_mode=\"max\",\n",
    "    checkoint_best=True,\n",
    "    writer=\"tensorboard\",\n",
    "    optimizer=\"adamax\",\n",
    "    lr=5e-5,\n",
    "    l2=1e-3,\n",
    "    log_every=0.1, \n",
    "    score_every=0.1,\n",
    "    n_epochs=10,\n",
    "    progress_bar=True,\n",
    "    checkpoint_best=True,\n",
    "    checkpoint_cleanup=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate baseline slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_set RTE_slice:dash_semicolon now points to task RTE (originally, RTE_slice:dash_semicolon).\n",
      "label_set RTE_slice:more_people now points to task RTE (originally, RTE_slice:more_people).\n",
      "label_set RTE_slice:BASE now points to task RTE (originally, RTE_slice:BASE).\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "eval_payload = copy.deepcopy(payloads_slice[1])\n",
    "\n",
    "# NOTE: we need to retarget slices to the original RTE head\n",
    "for label_name in ['RTE_slice:dash_semicolon', 'RTE_slice:more_people', 'RTE_slice:BASE']:\n",
    "    eval_payload.retarget_labelset(label_name, 'RTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Payload(RTE_valid: labels_to_tasks=[{'RTE_gold': 'RTE', 'RTE_slice:dash_semicolon': 'RTE', 'RTE_slice:more_people': 'RTE', 'RTE_slice:BASE': 'RTE'}], split=valid)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RTE/RTE_valid/RTE_gold/accuracy': 0.703971119133574,\n",
       " 'RTE/RTE_valid/RTE_slice:dash_semicolon/accuracy': 0.6293103448275862,\n",
       " 'RTE/RTE_valid/RTE_slice:more_people/accuracy': 0.5,\n",
       " 'RTE/RTE_valid/RTE_slice:BASE/accuracy': 0.703971119133574}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(eval_payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and train slice model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tasks_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modifying RTE out_features from 2 -> 1\n",
      "Modifying RTE_slice:dash_semicolon out_features from 2 -> 1\n",
      "Modifying RTE_slice:more_people out_features from 2 -> 1\n",
      "Modifying RTE_slice:BASE out_features from 2 -> 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[BinaryClassificationTask(name=RTE, loss_multiplier=1.00, is_slice=False),\n",
       " BinaryClassificationTask(name=RTE_slice:dash_semicolon, loss_multiplier=1.00, is_slice=True),\n",
       " BinaryClassificationTask(name=RTE_slice:more_people, loss_multiplier=1.00, is_slice=True),\n",
       " BinaryClassificationTask(name=RTE_slice:BASE, loss_multiplier=1.00, is_slice=True)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metal.mmtl.slicing.slicing_tasks import convert_to_slicing_tasks\n",
    "slicing_tasks = convert_to_slicing_tasks(tasks_slice)\n",
    "slicing_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SliceModel(\n",
       "  (input_modules): ModuleDict(\n",
       "    (RTE): DataParallel(\n",
       "      (module): BertRaw(\n",
       "        (embeddings): BertEmbeddings(\n",
       "          (word_embeddings): Embedding(28996, 768)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (token_type_embeddings): Embedding(2, 768)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (encoder): BertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (1): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (2): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (3): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (4): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (5): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (6): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (7): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (8): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (9): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (10): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (11): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): BertPooler(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (RTE_slice:BASE): DataParallel(\n",
       "      (module): BertRaw(\n",
       "        (embeddings): BertEmbeddings(\n",
       "          (word_embeddings): Embedding(28996, 768)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (token_type_embeddings): Embedding(2, 768)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (encoder): BertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (1): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (2): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (3): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (4): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (5): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (6): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (7): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (8): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (9): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (10): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (11): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): BertPooler(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (RTE_slice:dash_semicolon): DataParallel(\n",
       "      (module): BertRaw(\n",
       "        (embeddings): BertEmbeddings(\n",
       "          (word_embeddings): Embedding(28996, 768)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (token_type_embeddings): Embedding(2, 768)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (encoder): BertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (1): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (2): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (3): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (4): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (5): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (6): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (7): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (8): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (9): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (10): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (11): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): BertPooler(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (RTE_slice:more_people): DataParallel(\n",
       "      (module): BertRaw(\n",
       "        (embeddings): BertEmbeddings(\n",
       "          (word_embeddings): Embedding(28996, 768)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (token_type_embeddings): Embedding(2, 768)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (encoder): BertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (1): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (2): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (3): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (4): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (5): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (6): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (7): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (8): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (9): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (10): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (11): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): BertPooler(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_modules): ModuleDict(\n",
       "    (RTE): DataParallel(\n",
       "      (module): BertExtractCls(\n",
       "        (pooler): BertPooler(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "    )\n",
       "    (RTE_slice:BASE): DataParallel(\n",
       "      (module): BertExtractCls(\n",
       "        (pooler): BertPooler(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "    )\n",
       "    (RTE_slice:dash_semicolon): DataParallel(\n",
       "      (module): BertExtractCls(\n",
       "        (pooler): BertPooler(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "    )\n",
       "    (RTE_slice:more_people): DataParallel(\n",
       "      (module): BertExtractCls(\n",
       "        (pooler): BertPooler(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (attention_modules): ModuleDict(\n",
       "    (RTE): DataParallel(\n",
       "      (module): MetalModuleWrapper(\n",
       "        (module): IdentityModule()\n",
       "      )\n",
       "    )\n",
       "    (RTE_slice:BASE): DataParallel(\n",
       "      (module): MetalModuleWrapper(\n",
       "        (module): IdentityModule()\n",
       "      )\n",
       "    )\n",
       "    (RTE_slice:dash_semicolon): DataParallel(\n",
       "      (module): MetalModuleWrapper(\n",
       "        (module): IdentityModule()\n",
       "      )\n",
       "    )\n",
       "    (RTE_slice:more_people): DataParallel(\n",
       "      (module): MetalModuleWrapper(\n",
       "        (module): IdentityModule()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head_modules): ModuleDict(\n",
       "    (RTE): DataParallel(\n",
       "      (module): MetalModuleWrapper(\n",
       "        (module): Linear(in_features=768, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (RTE_slice:BASE): DataParallel(\n",
       "      (module): MetalModuleWrapper(\n",
       "        (module): Linear(in_features=768, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (RTE_slice:dash_semicolon): DataParallel(\n",
       "      (module): MetalModuleWrapper(\n",
       "        (module): Linear(in_features=768, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (RTE_slice:more_people): DataParallel(\n",
       "      (module): MetalModuleWrapper(\n",
       "        (module): Linear(in_features=768, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = MetalModel(tasks_slice, seed=SEED, verbose=False)\n",
    "slice_model = SliceModel(slicing_tasks, seed=SEED, verbose=False)\n",
    "slice_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning train loop.\n",
      "Expecting a total of approximately 2496 examples and 312 batches per epoch from 1 payload(s) in the train split.\n",
      "Writing config to /dfs/scratch0/vschen/metal-mmtl/logs/2019_04_15/22_03_58/config.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "736a93d3a1d7411a9c0f7767bd8a7699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/scratch0/vschen/venv-mmtl/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10 epo]: RTE:[RTE_train/RTE_gold/loss=6.91e-01, RTE_valid/RTE_gold/accuracy=5.27e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.52e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.13e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.79e-01, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.87e-01, train/all/lr=1.00e-05]\n",
      "Saving model at iteration 0.10 with best (max) score RTE/RTE_valid/RTE_gold/accuracy=0.527\n",
      "[0.21 epo]: RTE:[RTE_train/RTE_gold/loss=6.93e-01, RTE_valid/RTE_gold/accuracy=5.27e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.95e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.29e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.94e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=2.08e-01, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.99e-01, train/all/lr=1.00e-05]\n",
      "[0.31 epo]: RTE:[RTE_train/RTE_gold/loss=6.90e-01, RTE_valid/RTE_gold/accuracy=5.27e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.69e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.21e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.77e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.46e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.89e-01, train/all/lr=1.00e-05]\n",
      "[0.41 epo]: RTE:[RTE_train/RTE_gold/loss=6.91e-01, RTE_valid/RTE_gold/accuracy=5.27e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.58e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.29e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.69e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.76e-01, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.84e-01, train/all/lr=1.00e-05]\n",
      "[0.51 epo]: RTE:[RTE_train/RTE_gold/loss=6.92e-01, RTE_valid/RTE_gold/accuracy=5.27e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.99e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.21e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.87e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.28e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.97e-01, train/all/lr=1.00e-05]\n",
      "[0.62 epo]: RTE:[RTE_train/RTE_gold/loss=6.91e-01, RTE_valid/RTE_gold/accuracy=5.27e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.71e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.90e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.51e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.97e-01, train/all/lr=1.00e-05]\n",
      "[0.72 epo]: RTE:[RTE_train/RTE_gold/loss=6.92e-01, RTE_valid/RTE_gold/accuracy=5.27e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.75e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.81e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.07e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.90e-01, train/all/lr=1.00e-05]\n",
      "[0.82 epo]: RTE:[RTE_train/RTE_gold/loss=6.91e-01, RTE_valid/RTE_gold/accuracy=5.27e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.82e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.86e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.86e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.77e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.92e-01, train/all/lr=1.00e-05]\n",
      "[0.92 epo]: RTE:[RTE_train/RTE_gold/loss=6.92e-01, RTE_valid/RTE_gold/accuracy=5.27e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.64e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.73e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=3.04e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.89e-01, train/all/lr=1.00e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d5dc0f61fe494ca4e5d9666c2fc9e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.03 epo]: RTE:[RTE_train/RTE_gold/loss=6.91e-01, RTE_valid/RTE_gold/accuracy=5.27e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.52e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.71e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.34e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.81e-01, train/all/lr=1.00e-05]\n",
      "[1.13 epo]: RTE:[RTE_train/RTE_gold/loss=6.90e-01, RTE_valid/RTE_gold/accuracy=5.27e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.22e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.21e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.52e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.78e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.70e-01, train/all/lr=1.00e-05]\n",
      "[1.23 epo]: RTE:[RTE_train/RTE_gold/loss=6.91e-01, RTE_valid/RTE_gold/accuracy=5.27e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.53e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.77e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.33e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.88e-01, train/all/lr=1.00e-05]\n",
      "[1.33 epo]: RTE:[RTE_train/RTE_gold/loss=6.90e-01, RTE_valid/RTE_gold/accuracy=5.27e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.51e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.78e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.63e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.54e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.77e-01, train/all/lr=1.00e-05]\n",
      "[1.44 epo]: RTE:[RTE_train/RTE_gold/loss=6.91e-01, RTE_valid/RTE_gold/accuracy=5.31e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.55e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.64e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=3.12e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.75e-01, train/all/lr=1.00e-05]\n",
      "Saving model at iteration 1.44 with best (max) score RTE/RTE_valid/RTE_gold/accuracy=0.531\n",
      "[1.54 epo]: RTE:[RTE_train/RTE_gold/loss=6.90e-01, RTE_valid/RTE_gold/accuracy=5.31e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.37e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.78e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.64e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.26e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.79e-01, train/all/lr=1.00e-05]\n",
      "[1.64 epo]: RTE:[RTE_train/RTE_gold/loss=6.90e-01, RTE_valid/RTE_gold/accuracy=5.38e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.48e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.61e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=3.96e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.76e-01, train/all/lr=1.00e-05]\n",
      "Saving model at iteration 1.64 with best (max) score RTE/RTE_valid/RTE_gold/accuracy=0.538\n",
      "[1.74 epo]: RTE:[RTE_train/RTE_gold/loss=6.90e-01, RTE_valid/RTE_gold/accuracy=5.42e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.57e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.57e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.25e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.77e-01, train/all/lr=1.00e-05]\n",
      "Saving model at iteration 1.74 with best (max) score RTE/RTE_valid/RTE_gold/accuracy=0.542\n",
      "[1.85 epo]: RTE:[RTE_train/RTE_gold/loss=6.90e-01, RTE_valid/RTE_gold/accuracy=5.42e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.45e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.54e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.72e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.70e-01, train/all/lr=1.00e-05]\n",
      "[1.95 epo]: RTE:[RTE_train/RTE_gold/loss=6.90e-01, RTE_valid/RTE_gold/accuracy=5.38e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.50e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.78e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.81e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.88e-01, train/all/lr=1.00e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c7de77e9b5e4bcbac38159d3fcd47b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.05 epo]: RTE:[RTE_train/RTE_gold/loss=6.90e-01, RTE_valid/RTE_gold/accuracy=5.45e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.43e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.68e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.79e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.86e-01, train/all/lr=1.00e-05]\n",
      "Saving model at iteration 2.05 with best (max) score RTE/RTE_valid/RTE_gold/accuracy=0.545\n",
      "[2.15 epo]: RTE:[RTE_train/RTE_gold/loss=6.89e-01, RTE_valid/RTE_gold/accuracy=5.96e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.06e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.21e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.35e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.97e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.58e-01, train/all/lr=1.00e-05]\n",
      "Saving model at iteration 2.15 with best (max) score RTE/RTE_valid/RTE_gold/accuracy=0.596\n",
      "[2.26 epo]: RTE:[RTE_train/RTE_gold/loss=6.88e-01, RTE_valid/RTE_gold/accuracy=5.74e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.00e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.28e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.98e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.53e-01, train/all/lr=1.00e-05]\n",
      "[2.36 epo]: RTE:[RTE_train/RTE_gold/loss=6.90e-01, RTE_valid/RTE_gold/accuracy=6.10e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.44e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.58e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=3.02e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.80e-01, train/all/lr=1.00e-05]\n",
      "Saving model at iteration 2.36 with best (max) score RTE/RTE_valid/RTE_gold/accuracy=0.610\n",
      "[2.46 epo]: RTE:[RTE_train/RTE_gold/loss=6.89e-01, RTE_valid/RTE_gold/accuracy=5.99e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.45e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.63e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.93e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.75e-01, train/all/lr=1.00e-05]\n",
      "[2.56 epo]: RTE:[RTE_train/RTE_gold/loss=6.89e-01, RTE_valid/RTE_gold/accuracy=6.28e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.12e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.29e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.52e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.51e-01, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.72e-01, train/all/lr=1.00e-05]\n",
      "Saving model at iteration 2.56 with best (max) score RTE/RTE_valid/RTE_gold/accuracy=0.628\n",
      "[2.67 epo]: RTE:[RTE_train/RTE_gold/loss=6.88e-01, RTE_valid/RTE_gold/accuracy=5.88e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.45e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.86e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.70e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.85e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.81e-01, train/all/lr=1.00e-05]\n",
      "[2.77 epo]: RTE:[RTE_train/RTE_gold/loss=6.88e-01, RTE_valid/RTE_gold/accuracy=6.17e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.21e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.21e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.48e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.93e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.64e-01, train/all/lr=1.00e-05]\n",
      "[2.87 epo]: RTE:[RTE_train/RTE_gold/loss=6.89e-01, RTE_valid/RTE_gold/accuracy=6.06e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.39e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.45e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.27e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.65e-01, train/all/lr=1.00e-05]\n",
      "[2.97 epo]: RTE:[RTE_train/RTE_gold/loss=6.89e-01, RTE_valid/RTE_gold/accuracy=6.39e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.16e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.21e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.48e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.83e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.68e-01, train/all/lr=1.00e-05]\n",
      "Saving model at iteration 2.97 with best (max) score RTE/RTE_valid/RTE_gold/accuracy=0.639\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d66bb4456194776ae080f0c7802d8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.08 epo]: RTE:[RTE_train/RTE_gold/loss=6.87e-01, RTE_valid/RTE_gold/accuracy=6.06e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.17e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.28e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.88e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.53e-01, train/all/lr=1.00e-05]\n",
      "[3.18 epo]: RTE:[RTE_train/RTE_gold/loss=6.88e-01, RTE_valid/RTE_gold/accuracy=6.61e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.20e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.29e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.35e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.55e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.63e-01, train/all/lr=1.00e-05]\n",
      "Saving model at iteration 3.18 with best (max) score RTE/RTE_valid/RTE_gold/accuracy=0.661\n",
      "[3.28 epo]: RTE:[RTE_train/RTE_gold/loss=6.87e-01, RTE_valid/RTE_gold/accuracy=6.14e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.20e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.21e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.49e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.05e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.64e-01, train/all/lr=1.00e-05]\n",
      "[3.38 epo]: RTE:[RTE_train/RTE_gold/loss=6.86e-01, RTE_valid/RTE_gold/accuracy=6.43e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=9.70e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.29e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.19e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.96e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.51e-01, train/all/lr=1.00e-05]\n",
      "[3.49 epo]: RTE:[RTE_train/RTE_gold/loss=6.87e-01, RTE_valid/RTE_gold/accuracy=6.39e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.00e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.38e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.11e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.52e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.47e-01, train/all/lr=1.00e-05]\n",
      "[3.59 epo]: RTE:[RTE_train/RTE_gold/loss=6.88e-01, RTE_valid/RTE_gold/accuracy=6.39e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.22e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.69e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.50e-01, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.64e-01, train/all/lr=1.00e-05]\n",
      "[3.69 epo]: RTE:[RTE_train/RTE_gold/loss=6.87e-01, RTE_valid/RTE_gold/accuracy=6.35e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=9.61e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.29e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.53e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.55e-01, train/all/lr=1.00e-05]\n",
      "[3.79 epo]: RTE:[RTE_train/RTE_gold/loss=6.87e-01, RTE_valid/RTE_gold/accuracy=6.57e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=9.28e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.32e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=3.39e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.56e-01, train/all/lr=1.00e-05]\n",
      "[3.90 epo]: RTE:[RTE_train/RTE_gold/loss=6.86e-01, RTE_valid/RTE_gold/accuracy=6.32e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.27e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.52e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.67e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.70e-01, train/all/lr=1.00e-05]\n",
      "[4.0 epo]: RTE:[RTE_train/RTE_gold/loss=6.87e-01, RTE_valid/RTE_gold/accuracy=6.03e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.11e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.31e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.45e-01, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.65e-01, train/all/lr=1.00e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b54d0ab46e84bcf8c11717e1335f2e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.10 epo]: RTE:[RTE_train/RTE_gold/loss=6.86e-01, RTE_valid/RTE_gold/accuracy=6.50e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=8.91e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.21e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.60e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.49e-01, train/all/lr=1.00e-05]\n",
      "[4.21 epo]: RTE:[RTE_train/RTE_gold/loss=6.85e-01, RTE_valid/RTE_gold/accuracy=6.25e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.08e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.26e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.41e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.52e-01, train/all/lr=1.00e-05]\n",
      "[4.31 epo]: RTE:[RTE_train/RTE_gold/loss=6.85e-01, RTE_valid/RTE_gold/accuracy=6.28e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=7.54e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.21e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.02e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.78e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.38e-01, train/all/lr=1.00e-05]\n",
      "[4.41 epo]: RTE:[RTE_train/RTE_gold/loss=6.84e-01, RTE_valid/RTE_gold/accuracy=6.32e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=9.05e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.01e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.99e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.43e-01, train/all/lr=1.00e-05]\n",
      "[4.51 epo]: RTE:[RTE_train/RTE_gold/loss=6.84e-01, RTE_valid/RTE_gold/accuracy=6.21e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.22e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.78e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.81e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.19e-01, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.52e-01, train/all/lr=1.00e-05]\n",
      "[4.62 epo]: RTE:[RTE_train/RTE_gold/loss=6.84e-01, RTE_valid/RTE_gold/accuracy=6.32e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=8.57e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.08e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.98e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.43e-01, train/all/lr=1.00e-05]\n",
      "[4.72 epo]: RTE:[RTE_train/RTE_gold/loss=6.85e-01, RTE_valid/RTE_gold/accuracy=6.57e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.13e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.21e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.25e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.05e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.53e-01, train/all/lr=1.00e-05]\n",
      "[4.82 epo]: RTE:[RTE_train/RTE_gold/loss=6.85e-01, RTE_valid/RTE_gold/accuracy=6.28e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=9.07e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.22e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=3.61e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.52e-01, train/all/lr=1.00e-05]\n",
      "[4.92 epo]: RTE:[RTE_train/RTE_gold/loss=6.85e-01, RTE_valid/RTE_gold/accuracy=6.53e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=9.30e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.36e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.10e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.58e-01, train/all/lr=1.00e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e1796b9f5b4933820eb952548e66c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.03 epo]: RTE:[RTE_train/RTE_gold/loss=6.85e-01, RTE_valid/RTE_gold/accuracy=6.43e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=7.58e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.27e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.55e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.50e-01, train/all/lr=1.00e-05]\n",
      "[5.13 epo]: RTE:[RTE_train/RTE_gold/loss=6.84e-01, RTE_valid/RTE_gold/accuracy=6.86e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.04e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.24e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.73e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.54e-01, train/all/lr=1.00e-05]\n",
      "Saving model at iteration 5.13 with best (max) score RTE/RTE_valid/RTE_gold/accuracy=0.686\n",
      "[5.23 epo]: RTE:[RTE_train/RTE_gold/loss=6.84e-01, RTE_valid/RTE_gold/accuracy=6.35e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=7.07e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.22e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.51e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.46e-01, train/all/lr=1.00e-05]\n",
      "[5.33 epo]: RTE:[RTE_train/RTE_gold/loss=6.83e-01, RTE_valid/RTE_gold/accuracy=6.86e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=7.08e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.81e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=9.66e-02, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.34e-01, train/all/lr=1.00e-05]\n",
      "[5.44 epo]: RTE:[RTE_train/RTE_gold/loss=6.83e-01, RTE_valid/RTE_gold/accuracy=6.64e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=7.67e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.21e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.12e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.08e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.47e-01, train/all/lr=1.00e-05]\n",
      "[5.54 epo]: RTE:[RTE_train/RTE_gold/loss=6.83e-01, RTE_valid/RTE_gold/accuracy=6.71e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=7.08e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.21e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.25e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.02e-01, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.33e-01, train/all/lr=1.00e-05]\n",
      "[5.64 epo]: RTE:[RTE_train/RTE_gold/loss=6.83e-01, RTE_valid/RTE_gold/accuracy=6.79e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.28e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.31e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.55e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.55e-01, train/all/lr=1.00e-05]\n",
      "[5.74 epo]: RTE:[RTE_train/RTE_gold/loss=6.84e-01, RTE_valid/RTE_gold/accuracy=6.57e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.04e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.21e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.16e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.29e-01, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.56e-01, train/all/lr=1.00e-05]\n",
      "[5.85 epo]: RTE:[RTE_train/RTE_gold/loss=6.84e-01, RTE_valid/RTE_gold/accuracy=6.35e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.38e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.99e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.46e-01, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.65e-01, train/all/lr=1.00e-05]\n",
      "[5.95 epo]: RTE:[RTE_train/RTE_gold/loss=6.83e-01, RTE_valid/RTE_gold/accuracy=6.75e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=5.62e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.13e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.21e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.37e-01, train/all/lr=1.00e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6acb91c37cc541709bd52a615a287f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.05 epo]: RTE:[RTE_train/RTE_gold/loss=6.83e-01, RTE_valid/RTE_gold/accuracy=6.50e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=8.31e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.03e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=3.04e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.43e-01, train/all/lr=1.00e-05]\n",
      "[6.15 epo]: RTE:[RTE_train/RTE_gold/loss=6.82e-01, RTE_valid/RTE_gold/accuracy=6.64e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=7.54e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.78e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=9.72e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.67e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.41e-01, train/all/lr=1.00e-05]\n",
      "[6.26 epo]: RTE:[RTE_train/RTE_gold/loss=6.82e-01, RTE_valid/RTE_gold/accuracy=6.57e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.05e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.86e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.34e-01, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.13e-01, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.44e-01, train/all/lr=1.00e-05]\n",
      "[6.36 epo]: RTE:[RTE_train/RTE_gold/loss=6.81e-01, RTE_valid/RTE_gold/accuracy=6.82e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.07e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.78e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=9.85e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.80e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.31e-01, train/all/lr=1.00e-05]\n",
      "[6.46 epo]: RTE:[RTE_train/RTE_gold/loss=6.81e-01, RTE_valid/RTE_gold/accuracy=6.53e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.07e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=7.95e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.13e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.48e-01, train/all/lr=1.00e-05]\n",
      "[6.56 epo]: RTE:[RTE_train/RTE_gold/loss=6.80e-01, RTE_valid/RTE_gold/accuracy=6.68e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=7.33e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.78e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.04e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.98e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.39e-01, train/all/lr=1.00e-05]\n",
      "[6.67 epo]: RTE:[RTE_train/RTE_gold/loss=6.82e-01, RTE_valid/RTE_gold/accuracy=6.50e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=8.37e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.69e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.19e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.39e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.45e-01, train/all/lr=1.00e-05]\n",
      "[6.77 epo]: RTE:[RTE_train/RTE_gold/loss=6.82e-01, RTE_valid/RTE_gold/accuracy=6.86e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=8.36e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.36e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.34e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.50e-01, train/all/lr=1.00e-05]\n",
      "[6.87 epo]: RTE:[RTE_train/RTE_gold/loss=6.79e-01, RTE_valid/RTE_gold/accuracy=6.25e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=5.75e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=7.82e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.47e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.24e-01, train/all/lr=1.00e-05]\n",
      "[6.97 epo]: RTE:[RTE_train/RTE_gold/loss=6.81e-01, RTE_valid/RTE_gold/accuracy=6.68e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=8.02e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.86e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.04e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.29e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.29e-01, train/all/lr=1.00e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f789a96c82454b1e919c6e0b0952e51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.08 epo]: RTE:[RTE_train/RTE_gold/loss=6.81e-01, RTE_valid/RTE_gold/accuracy=6.75e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.87e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.09e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.28e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.43e-01, train/all/lr=1.00e-05]\n",
      "[7.18 epo]: RTE:[RTE_train/RTE_gold/loss=6.79e-01, RTE_valid/RTE_gold/accuracy=6.79e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=4.76e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.86e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=9.20e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.56e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.28e-01, train/all/lr=1.00e-05]\n",
      "[7.28 epo]: RTE:[RTE_train/RTE_gold/loss=6.80e-01, RTE_valid/RTE_gold/accuracy=6.61e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=8.20e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.21e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.73e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.18e-01, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.45e-01, train/all/lr=1.00e-05]\n",
      "[7.38 epo]: RTE:[RTE_train/RTE_gold/loss=6.79e-01, RTE_valid/RTE_gold/accuracy=6.43e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.01e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=9.73e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.23e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.36e-01, train/all/lr=1.00e-05]\n",
      "[7.49 epo]: RTE:[RTE_train/RTE_gold/loss=6.80e-01, RTE_valid/RTE_gold/accuracy=6.64e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=9.06e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=8.76e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.05e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.28e-01, train/all/lr=1.00e-05]\n",
      "[7.59 epo]: RTE:[RTE_train/RTE_gold/loss=6.78e-01, RTE_valid/RTE_gold/accuracy=6.57e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=8.01e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=9.06e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.16e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.32e-01, train/all/lr=1.00e-05]\n",
      "[7.69 epo]: RTE:[RTE_train/RTE_gold/loss=6.79e-01, RTE_valid/RTE_gold/accuracy=6.75e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.45e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.86e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=9.75e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.19e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.37e-01, train/all/lr=1.00e-05]\n",
      "[7.79 epo]: RTE:[RTE_train/RTE_gold/loss=6.78e-01, RTE_valid/RTE_gold/accuracy=6.97e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=3.87e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.29e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=8.72e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.24e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.23e-01, train/all/lr=1.00e-05]\n",
      "Saving model at iteration 7.79 with best (max) score RTE/RTE_valid/RTE_gold/accuracy=0.697\n",
      "[7.90 epo]: RTE:[RTE_train/RTE_gold/loss=6.78e-01, RTE_valid/RTE_gold/accuracy=6.86e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.95e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=9.68e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.70e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.34e-01, train/all/lr=1.00e-05]\n",
      "[8.0 epo]: RTE:[RTE_train/RTE_gold/loss=6.79e-01, RTE_valid/RTE_gold/accuracy=6.71e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.71e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.14e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.87e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.39e-01, train/all/lr=1.00e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b168b75e02646d9b92e61e93a8e6e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.10 epo]: RTE:[RTE_train/RTE_gold/loss=6.76e-01, RTE_valid/RTE_gold/accuracy=6.46e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.18e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=7.98e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.28e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.28e-01, train/all/lr=1.00e-05]\n",
      "[8.21 epo]: RTE:[RTE_train/RTE_gold/loss=6.77e-01, RTE_valid/RTE_gold/accuracy=6.79e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=7.05e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=8.08e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.06e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.25e-01, train/all/lr=1.00e-05]\n",
      "[8.31 epo]: RTE:[RTE_train/RTE_gold/loss=6.76e-01, RTE_valid/RTE_gold/accuracy=6.71e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=5.78e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.86e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.08e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=8.17e-02, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.18e-01, train/all/lr=1.00e-05]\n",
      "[8.41 epo]: RTE:[RTE_train/RTE_gold/loss=6.78e-01, RTE_valid/RTE_gold/accuracy=6.79e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=4.27e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.78e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.13e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=9.57e-02, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.23e-01, train/all/lr=1.00e-05]\n",
      "[8.51 epo]: RTE:[RTE_train/RTE_gold/loss=6.78e-01, RTE_valid/RTE_gold/accuracy=6.64e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=7.77e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.09e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.62e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.37e-01, train/all/lr=1.00e-05]\n",
      "[8.62 epo]: RTE:[RTE_train/RTE_gold/loss=6.77e-01, RTE_valid/RTE_gold/accuracy=6.64e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=7.13e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.29e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=9.59e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.14e-01, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=3.35e-01, train/all/lr=1.00e-05]\n",
      "[8.72 epo]: RTE:[RTE_train/RTE_gold/loss=6.77e-01, RTE_valid/RTE_gold/accuracy=6.90e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.12e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=9.65e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.00e-01, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=3.37e-01, train/all/lr=1.00e-05]\n",
      "[8.82 epo]: RTE:[RTE_train/RTE_gold/loss=6.76e-01, RTE_valid/RTE_gold/accuracy=6.71e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=8.62e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=9.01e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.07e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.34e-01, train/all/lr=1.00e-05]\n",
      "[8.92 epo]: RTE:[RTE_train/RTE_gold/loss=6.77e-01, RTE_valid/RTE_gold/accuracy=6.82e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.96e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.78e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.08e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.17e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.30e-01, train/all/lr=1.00e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49978cda362c4d71b674eb07a66da575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.03 epo]: RTE:[RTE_train/RTE_gold/loss=6.76e-01, RTE_valid/RTE_gold/accuracy=6.90e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.76e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.02e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.46e-01, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=3.38e-01, train/all/lr=1.00e-05]\n",
      "[9.13 epo]: RTE:[RTE_train/RTE_gold/loss=6.74e-01, RTE_valid/RTE_gold/accuracy=6.71e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.30e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.86e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.34e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=7.68e-02, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.22e-01, train/all/lr=1.00e-05]\n",
      "[9.23 epo]: RTE:[RTE_train/RTE_gold/loss=6.75e-01, RTE_valid/RTE_gold/accuracy=6.50e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=2.84e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=8.66e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.31e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.29e-01, train/all/lr=1.00e-05]\n",
      "[9.33 epo]: RTE:[RTE_train/RTE_gold/loss=6.75e-01, RTE_valid/RTE_gold/accuracy=6.39e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.48e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.21e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.89e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.03e-01, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.30e-01, train/all/lr=1.00e-05]\n",
      "[9.44 epo]: RTE:[RTE_train/RTE_gold/loss=6.75e-01, RTE_valid/RTE_gold/accuracy=6.64e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=4.56e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.38e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=9.28e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.60e-01, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=3.22e-01, train/all/lr=1.00e-05]\n",
      "[9.54 epo]: RTE:[RTE_train/RTE_gold/loss=6.73e-01, RTE_valid/RTE_gold/accuracy=6.86e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=5.43e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=7.70e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.88e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.15e-01, train/all/lr=1.00e-05]\n",
      "[9.64 epo]: RTE:[RTE_train/RTE_gold/loss=6.75e-01, RTE_valid/RTE_gold/accuracy=6.39e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=9.88e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.47e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=9.48e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.17e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.34e-01, train/all/lr=1.00e-05]\n",
      "[9.74 epo]: RTE:[RTE_train/RTE_gold/loss=6.75e-01, RTE_valid/RTE_gold/accuracy=6.90e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=9.27e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.86e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.04e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.29e-01, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=3.39e-01, train/all/lr=1.00e-05]\n",
      "[9.85 epo]: RTE:[RTE_train/RTE_gold/loss=6.73e-01, RTE_valid/RTE_gold/accuracy=6.90e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.33e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=8.85e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.24e-01, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=3.27e-01, train/all/lr=1.00e-05]\n",
      "[9.95 epo]: RTE:[RTE_train/RTE_gold/loss=6.74e-01, RTE_valid/RTE_gold/accuracy=6.82e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=7.08e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.21e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=9.15e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=9.67e-02, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=3.30e-01, train/all/lr=1.00e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "337024abcf1d4bbf87da5490d1bc0f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.05 epo]: RTE:[RTE_train/RTE_gold/loss=6.73e-01, RTE_valid/RTE_gold/accuracy=6.75e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=5.51e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.21e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=9.43e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=9.42e-02, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=3.25e-01, train/all/lr=1.00e-05]\n",
      "[10.15 epo]: RTE:[RTE_train/RTE_gold/loss=6.71e-01, RTE_valid/RTE_gold/accuracy=6.75e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=3.25e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=6.87e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.94e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.17e-01, train/all/lr=1.00e-05]\n",
      "[10.26 epo]: RTE:[RTE_train/RTE_gold/loss=6.71e-01, RTE_valid/RTE_gold/accuracy=6.75e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.44e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.38e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=8.40e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.89e-01, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=3.21e-01, train/all/lr=1.00e-05]\n",
      "[10.36 epo]: RTE:[RTE_train/RTE_gold/loss=6.72e-01, RTE_valid/RTE_gold/accuracy=6.82e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=4.87e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.29e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.69e-01, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.09e-01, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.33e-01, train/all/lr=1.00e-05]\n",
      "[10.46 epo]: RTE:[RTE_train/RTE_gold/loss=6.72e-01, RTE_valid/RTE_gold/accuracy=6.57e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=5.07e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.38e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=8.47e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.16e-01, RTE_valid/RTE_slice:more_people/accuracy=7.50e-01] model:[train/all/loss=3.22e-01, train/all/lr=1.00e-05]\n",
      "[10.56 epo]: RTE:[RTE_train/RTE_gold/loss=6.72e-01, RTE_valid/RTE_gold/accuracy=6.61e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=5.93e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=9.44e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=8.80e-02, RTE_valid/RTE_slice:more_people/accuracy=8.33e-01] model:[train/all/loss=3.34e-01, train/all/lr=1.00e-05]\n",
      "[10.67 epo]: RTE:[RTE_train/RTE_gold/loss=6.71e-01, RTE_valid/RTE_gold/accuracy=6.71e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=8.20e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.28e-01, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=9.66e-02, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.27e-01, train/all/lr=1.00e-05]\n",
      "[10.77 epo]: RTE:[RTE_train/RTE_gold/loss=6.72e-01, RTE_valid/RTE_gold/accuracy=6.82e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.65e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=7.73e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.21e-01, RTE_valid/RTE_slice:more_people/accuracy=8.33e-01] model:[train/all/loss=3.22e-01, train/all/lr=1.00e-05]\n",
      "[10.87 epo]: RTE:[RTE_train/RTE_gold/loss=6.70e-01, RTE_valid/RTE_gold/accuracy=6.79e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=4.53e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=7.02e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.55e-01, RTE_valid/RTE_slice:more_people/accuracy=8.33e-01] model:[train/all/loss=3.14e-01, train/all/lr=1.00e-05]\n",
      "[10.97 epo]: RTE:[RTE_train/RTE_gold/loss=6.69e-01, RTE_valid/RTE_gold/accuracy=6.75e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=4.56e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=7.08e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.17e-01, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=3.13e-01, train/all/lr=1.00e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edbf4c8bfb8a473c90a20f68351947aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.08 epo]: RTE:[RTE_train/RTE_gold/loss=6.68e-01, RTE_valid/RTE_gold/accuracy=6.79e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.21e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=6.20e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=9.57e-02, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=3.07e-01, train/all/lr=1.00e-05]\n",
      "[11.18 epo]: RTE:[RTE_train/RTE_gold/loss=6.66e-01, RTE_valid/RTE_gold/accuracy=6.68e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=2.40e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=5.35e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.73e-01, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=3.03e-01, train/all/lr=1.00e-05]\n",
      "[11.28 epo]: RTE:[RTE_train/RTE_gold/loss=6.68e-01, RTE_valid/RTE_gold/accuracy=6.64e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=8.29e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=8.85e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.40e-01, RTE_valid/RTE_slice:more_people/accuracy=8.33e-01] model:[train/all/loss=3.28e-01, train/all/lr=1.00e-05]\n",
      "[11.38 epo]: RTE:[RTE_train/RTE_gold/loss=6.69e-01, RTE_valid/RTE_gold/accuracy=6.68e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=5.23e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=8.63e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.68e-01, RTE_valid/RTE_slice:more_people/accuracy=7.50e-01] model:[train/all/loss=3.19e-01, train/all/lr=1.00e-05]\n",
      "[11.49 epo]: RTE:[RTE_train/RTE_gold/loss=6.66e-01, RTE_valid/RTE_gold/accuracy=6.79e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=3.03e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.35e-01, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=5.63e-02, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.07e-01, train/all/lr=1.00e-05]\n",
      "[11.59 epo]: RTE:[RTE_train/RTE_gold/loss=6.66e-01, RTE_valid/RTE_gold/accuracy=6.79e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=4.03e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=6.45e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.47e-01, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=3.13e-01, train/all/lr=1.00e-05]\n",
      "[11.69 epo]: RTE:[RTE_train/RTE_gold/loss=6.65e-01, RTE_valid/RTE_gold/accuracy=6.79e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=4.43e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=6.51e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=9.38e-02, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=3.06e-01, train/all/lr=1.00e-05]\n",
      "[11.79 epo]: RTE:[RTE_train/RTE_gold/loss=6.65e-01, RTE_valid/RTE_gold/accuracy=6.61e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=5.50e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=8.05e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.61e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.19e-01, train/all/lr=1.00e-05]\n",
      "[11.90 epo]: RTE:[RTE_train/RTE_gold/loss=6.68e-01, RTE_valid/RTE_gold/accuracy=6.68e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.51e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=8.71e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=8.92e-02, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.26e-01, train/all/lr=1.00e-05]\n",
      "[12.0 epo]: RTE:[RTE_train/RTE_gold/loss=6.67e-01, RTE_valid/RTE_gold/accuracy=6.82e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.14e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.29e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.04e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.36e-01, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=3.35e-01, train/all/lr=1.00e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a786899100b2443b9d4fb13674bcb57b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.10 epo]: RTE:[RTE_train/RTE_gold/loss=6.63e-01, RTE_valid/RTE_gold/accuracy=6.86e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=4.21e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=6.21e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=8.12e-02, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=3.07e-01, train/all/lr=1.00e-05]\n",
      "[12.21 epo]: RTE:[RTE_train/RTE_gold/loss=6.64e-01, RTE_valid/RTE_gold/accuracy=6.71e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=4.75e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.78e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=7.26e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=9.14e-02, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=3.12e-01, train/all/lr=1.00e-05]\n",
      "[12.31 epo]: RTE:[RTE_train/RTE_gold/loss=6.63e-01, RTE_valid/RTE_gold/accuracy=6.68e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=4.86e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=6.28e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=9.46e-02, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=3.07e-01, train/all/lr=1.00e-05]\n",
      "[12.41 epo]: RTE:[RTE_train/RTE_gold/loss=6.63e-01, RTE_valid/RTE_gold/accuracy=6.61e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.05e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.78e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=7.56e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.57e-01, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=3.22e-01, train/all/lr=1.00e-05]\n",
      "[12.51 epo]: RTE:[RTE_train/RTE_gold/loss=6.63e-01, RTE_valid/RTE_gold/accuracy=6.53e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.25e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=6.47e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=8.73e-02, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=3.08e-01, train/all/lr=1.00e-05]\n",
      "[12.62 epo]: RTE:[RTE_train/RTE_gold/loss=6.63e-01, RTE_valid/RTE_gold/accuracy=6.64e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=5.15e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.61e-01, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=8.08e-02, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.18e-01, train/all/lr=1.00e-05]\n",
      "[12.72 epo]: RTE:[RTE_train/RTE_gold/loss=6.64e-01, RTE_valid/RTE_gold/accuracy=6.68e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=9.78e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=9.21e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.04e-01, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=3.32e-01, train/all/lr=1.00e-05]\n",
      "[12.82 epo]: RTE:[RTE_train/RTE_gold/loss=6.65e-01, RTE_valid/RTE_gold/accuracy=6.53e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=8.90e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.69e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.03e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.14e-01, RTE_valid/RTE_slice:more_people/accuracy=7.50e-01] model:[train/all/loss=3.30e-01, train/all/lr=1.00e-05]\n",
      "[12.92 epo]: RTE:[RTE_train/RTE_gold/loss=6.64e-01, RTE_valid/RTE_gold/accuracy=6.53e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=8.48e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.78e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.03e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.48e-01, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=3.31e-01, train/all/lr=1.00e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557fba75e7044f0f881444ad634bfdeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.03 epo]: RTE:[RTE_train/RTE_gold/loss=6.60e-01, RTE_valid/RTE_gold/accuracy=6.64e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=4.57e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.86e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=5.96e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.82e-01, RTE_valid/RTE_slice:more_people/accuracy=7.50e-01] model:[train/all/loss=3.05e-01, train/all/lr=1.00e-05]\n",
      "[13.13 epo]: RTE:[RTE_train/RTE_gold/loss=6.62e-01, RTE_valid/RTE_gold/accuracy=6.50e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.31e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.78e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=8.87e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=6.26e-02, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=3.27e-01, train/all/lr=1.00e-05]\n",
      "[13.23 epo]: RTE:[RTE_train/RTE_gold/loss=6.59e-01, RTE_valid/RTE_gold/accuracy=6.50e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=7.28e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.69e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.85e-01, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=6.76e-02, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.13e-01, train/all/lr=1.00e-05]\n",
      "[13.33 epo]: RTE:[RTE_train/RTE_gold/loss=6.59e-01, RTE_valid/RTE_gold/accuracy=6.61e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=4.66e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.60e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.45e-01, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=7.05e-02, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.10e-01, train/all/lr=1.00e-05]\n",
      "[13.44 epo]: RTE:[RTE_train/RTE_gold/loss=6.58e-01, RTE_valid/RTE_gold/accuracy=6.50e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=5.56e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.86e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=8.86e-02, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=7.20e-02, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.14e-01, train/all/lr=1.00e-05]\n",
      "[13.54 epo]: RTE:[RTE_train/RTE_gold/loss=6.61e-01, RTE_valid/RTE_gold/accuracy=6.46e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=7.85e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.78e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=8.67e-02, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=9.55e-02, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.18e-01, train/all/lr=1.00e-05]\n",
      "[13.64 epo]: RTE:[RTE_train/RTE_gold/loss=6.57e-01, RTE_valid/RTE_gold/accuracy=6.61e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=4.19e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.69e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=7.79e-02, RTE_valid/RTE_slice:more_people/accuracy=7.50e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=5.77e-02, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=2.96e-01, train/all/lr=1.00e-05]\n",
      "[13.74 epo]: RTE:[RTE_train/RTE_gold/loss=6.59e-01, RTE_valid/RTE_gold/accuracy=6.25e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=2.90e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.52e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=8.27e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=7.31e-02, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=3.10e-01, train/all/lr=1.00e-05]\n",
      "[13.85 epo]: RTE:[RTE_train/RTE_gold/loss=6.57e-01, RTE_valid/RTE_gold/accuracy=6.50e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=5.14e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.86e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=6.22e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.17e-01, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=3.05e-01, train/all/lr=1.00e-05]\n",
      "[13.95 epo]: RTE:[RTE_train/RTE_gold/loss=6.55e-01, RTE_valid/RTE_gold/accuracy=6.53e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.12e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.60e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=5.69e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=8.41e-02, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=3.07e-01, train/all/lr=1.00e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c212c08283448658d879ff5745cdc85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.05 epo]: RTE:[RTE_train/RTE_gold/loss=6.62e-01, RTE_valid/RTE_gold/accuracy=6.64e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=8.81e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.47e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.19e-01, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.39e-01, train/all/lr=1.00e-05]\n",
      "[14.15 epo]: RTE:[RTE_train/RTE_gold/loss=6.55e-01, RTE_valid/RTE_gold/accuracy=6.53e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=4.26e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.86e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=5.51e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.44e-01, RTE_valid/RTE_slice:more_people/accuracy=7.50e-01] model:[train/all/loss=2.99e-01, train/all/lr=1.00e-05]\n",
      "[14.26 epo]: RTE:[RTE_train/RTE_gold/loss=6.56e-01, RTE_valid/RTE_gold/accuracy=6.61e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.19e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.78e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=6.53e-02, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=7.55e-02, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.17e-01, train/all/lr=1.00e-05]\n",
      "[14.36 epo]: RTE:[RTE_train/RTE_gold/loss=6.56e-01, RTE_valid/RTE_gold/accuracy=6.61e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=7.96e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.86e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=7.62e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=9.21e-02, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=3.21e-01, train/all/lr=1.00e-05]\n",
      "[14.46 epo]: RTE:[RTE_train/RTE_gold/loss=6.53e-01, RTE_valid/RTE_gold/accuracy=6.64e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.36e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.86e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=6.91e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.49e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.09e-01, train/all/lr=1.00e-05]\n",
      "[14.56 epo]: RTE:[RTE_train/RTE_gold/loss=6.53e-01, RTE_valid/RTE_gold/accuracy=6.57e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.13e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.52e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=6.28e-02, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=5.99e-02, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.00e-01, train/all/lr=1.00e-05]\n",
      "[14.67 epo]: RTE:[RTE_train/RTE_gold/loss=6.52e-01, RTE_valid/RTE_gold/accuracy=6.43e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=5.63e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.43e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=5.42e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=6.68e-02, RTE_valid/RTE_slice:more_people/accuracy=7.50e-01] model:[train/all/loss=2.98e-01, train/all/lr=1.00e-05]\n",
      "[14.77 epo]: RTE:[RTE_train/RTE_gold/loss=6.56e-01, RTE_valid/RTE_gold/accuracy=6.57e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.21e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.69e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.05e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=7.36e-02, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=3.38e-01, train/all/lr=1.00e-05]\n",
      "[14.87 epo]: RTE:[RTE_train/RTE_gold/loss=6.55e-01, RTE_valid/RTE_gold/accuracy=6.64e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=8.47e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.86e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.85e-01, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=9.34e-02, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.20e-01, train/all/lr=1.00e-05]\n",
      "[14.97 epo]: RTE:[RTE_train/RTE_gold/loss=6.56e-01, RTE_valid/RTE_gold/accuracy=6.46e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=5.59e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.86e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=9.78e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=7.10e-02, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=3.22e-01, train/all/lr=1.00e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e20002692f47d0844ade98970e9996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.08 epo]: RTE:[RTE_train/RTE_gold/loss=6.49e-01, RTE_valid/RTE_gold/accuracy=6.46e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=3.70e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.86e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=5.28e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.90e-01, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=2.94e-01, train/all/lr=1.00e-05]\n",
      "[15.18 epo]: RTE:[RTE_train/RTE_gold/loss=6.52e-01, RTE_valid/RTE_gold/accuracy=6.57e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=7.27e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=6.68e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=8.06e-02, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=3.12e-01, train/all/lr=1.00e-05]\n",
      "[15.28 epo]: RTE:[RTE_train/RTE_gold/loss=6.51e-01, RTE_valid/RTE_gold/accuracy=6.53e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=3.23e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.86e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=8.29e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=5.72e-02, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=3.12e-01, train/all/lr=1.00e-05]\n",
      "[15.38 epo]: RTE:[RTE_train/RTE_gold/loss=6.53e-01, RTE_valid/RTE_gold/accuracy=6.32e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=7.17e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.60e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=9.73e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=5.72e-02, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=3.25e-01, train/all/lr=1.00e-05]\n",
      "[15.49 epo]: RTE:[RTE_train/RTE_gold/loss=6.54e-01, RTE_valid/RTE_gold/accuracy=6.46e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.12e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.78e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.05e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=8.92e-02, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=3.30e-01, train/all/lr=1.00e-05]\n",
      "[15.59 epo]: RTE:[RTE_train/RTE_gold/loss=6.49e-01, RTE_valid/RTE_gold/accuracy=6.71e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=7.06e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.78e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=6.84e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=8.57e-02, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=3.06e-01, train/all/lr=1.00e-05]\n",
      "[15.69 epo]: RTE:[RTE_train/RTE_gold/loss=6.47e-01, RTE_valid/RTE_gold/accuracy=6.86e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=3.24e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=4.83e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.29e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=2.89e-01, train/all/lr=1.00e-05]\n",
      "[15.79 epo]: RTE:[RTE_train/RTE_gold/loss=6.50e-01, RTE_valid/RTE_gold/accuracy=6.57e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=7.61e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.86e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=9.62e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.76e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.20e-01, train/all/lr=1.00e-05]\n",
      "[15.90 epo]: RTE:[RTE_train/RTE_gold/loss=6.49e-01, RTE_valid/RTE_gold/accuracy=6.61e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=3.79e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.69e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=8.68e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=6.77e-02, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=3.11e-01, train/all/lr=1.00e-05]\n",
      "[16.0 epo]: RTE:[RTE_train/RTE_gold/loss=6.52e-01, RTE_valid/RTE_gold/accuracy=6.53e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=8.29e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.78e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.01e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=5.54e-02, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=3.27e-01, train/all/lr=1.00e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d49a3dc89424309867e7c849b1a9d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16.10 epo]: RTE:[RTE_train/RTE_gold/loss=6.46e-01, RTE_valid/RTE_gold/accuracy=6.57e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=5.33e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=5.38e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.57e-01, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=3.01e-01, train/all/lr=1.00e-05]\n",
      "[16.21 epo]: RTE:[RTE_train/RTE_gold/loss=6.45e-01, RTE_valid/RTE_gold/accuracy=6.57e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=3.15e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=7.33e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=6.73e-02, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=3.06e-01, train/all/lr=1.00e-05]\n",
      "[16.31 epo]: RTE:[RTE_train/RTE_gold/loss=6.46e-01, RTE_valid/RTE_gold/accuracy=6.39e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.39e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.78e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=7.37e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=4.84e-02, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=3.02e-01, train/all/lr=1.00e-05]\n",
      "[16.41 epo]: RTE:[RTE_train/RTE_gold/loss=6.42e-01, RTE_valid/RTE_gold/accuracy=6.57e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=5.32e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.60e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=4.90e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=7.73e-02, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=2.94e-01, train/all/lr=1.00e-05]\n",
      "[16.51 epo]: RTE:[RTE_train/RTE_gold/loss=6.45e-01, RTE_valid/RTE_gold/accuracy=6.57e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=8.17e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=7.81e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=5.75e-02, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=3.11e-01, train/all/lr=1.00e-05]\n",
      "[16.62 epo]: RTE:[RTE_train/RTE_gold/loss=6.42e-01, RTE_valid/RTE_gold/accuracy=6.68e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.17e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.86e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=5.68e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.05e-01, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=3.07e-01, train/all/lr=1.00e-05]\n",
      "[16.72 epo]: RTE:[RTE_train/RTE_gold/loss=6.42e-01, RTE_valid/RTE_gold/accuracy=6.57e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=4.67e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=5.81e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.11e-01, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=2.91e-01, train/all/lr=1.00e-05]\n",
      "[16.82 epo]: RTE:[RTE_train/RTE_gold/loss=6.44e-01, RTE_valid/RTE_gold/accuracy=6.53e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=8.17e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=8.99e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=7.31e-02, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=3.15e-01, train/all/lr=1.00e-05]\n",
      "[16.92 epo]: RTE:[RTE_train/RTE_gold/loss=6.42e-01, RTE_valid/RTE_gold/accuracy=6.50e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=4.31e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=6.53e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=5.97e-02, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=2.97e-01, train/all/lr=1.00e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32d0c353f0d475ab9ffe84fa3050a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17.03 epo]: RTE:[RTE_train/RTE_gold/loss=6.46e-01, RTE_valid/RTE_gold/accuracy=6.28e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.29e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.52e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=1.09e-01, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.43e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=3.38e-01, train/all/lr=1.00e-05]\n",
      "[17.13 epo]: RTE:[RTE_train/RTE_gold/loss=6.42e-01, RTE_valid/RTE_gold/accuracy=6.61e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.71e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=4.57e-02, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=7.67e-02, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.07e-01, train/all/lr=1.00e-05]\n",
      "[17.23 epo]: RTE:[RTE_train/RTE_gold/loss=6.37e-01, RTE_valid/RTE_gold/accuracy=6.57e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.05e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.78e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=5.54e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=7.24e-02, RTE_valid/RTE_slice:more_people/accuracy=7.50e-01] model:[train/all/loss=2.98e-01, train/all/lr=1.00e-05]\n",
      "[17.33 epo]: RTE:[RTE_train/RTE_gold/loss=6.40e-01, RTE_valid/RTE_gold/accuracy=6.39e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=7.74e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.69e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=7.30e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.49e-01, RTE_valid/RTE_slice:more_people/accuracy=7.50e-01] model:[train/all/loss=3.04e-01, train/all/lr=1.00e-05]\n",
      "[17.44 epo]: RTE:[RTE_train/RTE_gold/loss=6.41e-01, RTE_valid/RTE_gold/accuracy=6.50e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=5.07e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=7.97e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=4.28e-02, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=3.06e-01, train/all/lr=1.00e-05]\n",
      "[17.54 epo]: RTE:[RTE_train/RTE_gold/loss=6.37e-01, RTE_valid/RTE_gold/accuracy=6.57e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=7.55e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=5.76e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=5.45e-02, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=2.97e-01, train/all/lr=1.00e-05]\n",
      "[17.64 epo]: RTE:[RTE_train/RTE_gold/loss=6.37e-01, RTE_valid/RTE_gold/accuracy=6.71e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=3.52e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.69e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=6.13e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=5.20e-02, RTE_valid/RTE_slice:more_people/accuracy=7.50e-01] model:[train/all/loss=2.92e-01, train/all/lr=1.00e-05]\n",
      "[17.74 epo]: RTE:[RTE_train/RTE_gold/loss=6.37e-01, RTE_valid/RTE_gold/accuracy=6.43e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=7.33e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=4.84e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=4.85e-02, RTE_valid/RTE_slice:more_people/accuracy=7.50e-01] model:[train/all/loss=3.04e-01, train/all/lr=1.00e-05]\n",
      "[17.85 epo]: RTE:[RTE_train/RTE_gold/loss=6.34e-01, RTE_valid/RTE_gold/accuracy=6.25e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=4.40e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.07e-01, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=6.86e-02, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=2.97e-01, train/all/lr=1.00e-05]\n",
      "[17.95 epo]: RTE:[RTE_train/RTE_gold/loss=6.36e-01, RTE_valid/RTE_gold/accuracy=6.17e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=7.71e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.69e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=6.35e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.45e-01, RTE_valid/RTE_slice:more_people/accuracy=8.33e-01] model:[train/all/loss=3.04e-01, train/all/lr=1.00e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede0c9d249834e249cfb63dd4481c54d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18.05 epo]: RTE:[RTE_train/RTE_gold/loss=6.36e-01, RTE_valid/RTE_gold/accuracy=6.53e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=8.87e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=9.58e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=4.27e-02, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=3.20e-01, train/all/lr=1.00e-05]\n",
      "[18.15 epo]: RTE:[RTE_train/RTE_gold/loss=6.31e-01, RTE_valid/RTE_gold/accuracy=6.53e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=3.72e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.86e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=5.25e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=4.42e-02, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=2.87e-01, train/all/lr=1.00e-05]\n",
      "[18.26 epo]: RTE:[RTE_train/RTE_gold/loss=6.33e-01, RTE_valid/RTE_gold/accuracy=6.39e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=4.70e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.69e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=6.95e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.93e-01, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=2.99e-01, train/all/lr=1.00e-05]\n",
      "[18.36 epo]: RTE:[RTE_train/RTE_gold/loss=6.30e-01, RTE_valid/RTE_gold/accuracy=6.43e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=5.68e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=2.32e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.78e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=4.77e-02, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=2.90e-01, train/all/lr=1.00e-05]\n",
      "[18.46 epo]: RTE:[RTE_train/RTE_gold/loss=6.32e-01, RTE_valid/RTE_gold/accuracy=6.25e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.19e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.86e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=7.56e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=8.99e-02, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.12e-01, train/all/lr=1.00e-05]\n",
      "[18.56 epo]: RTE:[RTE_train/RTE_gold/loss=6.33e-01, RTE_valid/RTE_gold/accuracy=6.14e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.34e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.60e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=8.73e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=6.85e-02, RTE_valid/RTE_slice:more_people/accuracy=7.50e-01] model:[train/all/loss=3.05e-01, train/all/lr=1.00e-05]\n",
      "[18.67 epo]: RTE:[RTE_train/RTE_gold/loss=6.31e-01, RTE_valid/RTE_gold/accuracy=6.28e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=9.40e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.31e-01, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=8.16e-02, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.07e-01, train/all/lr=1.00e-05]\n",
      "[18.77 epo]: RTE:[RTE_train/RTE_gold/loss=6.34e-01, RTE_valid/RTE_gold/accuracy=6.35e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=7.96e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.95e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=9.13e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=7.38e-02, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] model:[train/all/loss=3.11e-01, train/all/lr=1.00e-05]\n",
      "[18.87 epo]: RTE:[RTE_train/RTE_gold/loss=6.29e-01, RTE_valid/RTE_gold/accuracy=6.39e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=2.33e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=6.70e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=6.01e-02, RTE_valid/RTE_slice:more_people/accuracy=4.17e-01] model:[train/all/loss=2.94e-01, train/all/lr=1.00e-05]\n",
      "[18.97 epo]: RTE:[RTE_train/RTE_gold/loss=6.30e-01, RTE_valid/RTE_gold/accuracy=6.17e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=7.67e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.69e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=8.36e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=4.99e-02, RTE_valid/RTE_slice:more_people/accuracy=7.50e-01] model:[train/all/loss=3.07e-01, train/all/lr=1.00e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d42d14ce264c7c810f5c32ac4fb4e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19.08 epo]: RTE:[RTE_train/RTE_gold/loss=6.29e-01, RTE_valid/RTE_gold/accuracy=6.57e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.13e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=4.52e-02, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=8.92e-02, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.24e-01, train/all/lr=1.00e-05]\n",
      "[19.18 epo]: RTE:[RTE_train/RTE_gold/loss=6.25e-01, RTE_valid/RTE_gold/accuracy=6.61e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=5.19e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.29e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=7.45e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=4.07e-02, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.00e-01, train/all/lr=1.00e-05]\n",
      "[19.28 epo]: RTE:[RTE_train/RTE_gold/loss=6.28e-01, RTE_valid/RTE_gold/accuracy=6.61e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=1.66e-01, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=5.82e-02, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=8.80e-02, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=3.23e-01, train/all/lr=1.00e-05]\n",
      "[19.38 epo]: RTE:[RTE_train/RTE_gold/loss=6.24e-01, RTE_valid/RTE_gold/accuracy=6.64e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.55e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.21e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=7.17e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=4.28e-02, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=2.96e-01, train/all/lr=1.00e-05]\n",
      "[19.49 epo]: RTE:[RTE_train/RTE_gold/loss=6.23e-01, RTE_valid/RTE_gold/accuracy=6.50e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=5.61e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.12e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=5.97e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=2.68e-02, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=2.91e-01, train/all/lr=1.00e-05]\n",
      "[19.59 epo]: RTE:[RTE_train/RTE_gold/loss=6.21e-01, RTE_valid/RTE_gold/accuracy=6.43e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.81e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.21e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=5.62e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.55e-01, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=2.92e-01, train/all/lr=1.00e-05]\n",
      "[19.69 epo]: RTE:[RTE_train/RTE_gold/loss=6.19e-01, RTE_valid/RTE_gold/accuracy=6.32e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=3.00e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=5.43e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=4.83e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=5.15e-02, RTE_valid/RTE_slice:more_people/accuracy=6.67e-01] model:[train/all/loss=2.77e-01, train/all/lr=1.00e-05]\n",
      "[19.79 epo]: RTE:[RTE_train/RTE_gold/loss=6.25e-01, RTE_valid/RTE_gold/accuracy=6.46e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=5.41e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.21e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=8.49e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=4.93e-02, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=3.00e-01, train/all/lr=1.00e-05]\n",
      "[19.90 epo]: RTE:[RTE_train/RTE_gold/loss=6.20e-01, RTE_valid/RTE_gold/accuracy=6.39e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=3.94e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.21e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=7.72e-02, RTE_valid/RTE_slice:BASE/accuracy=0] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=1.14e-01, RTE_valid/RTE_slice:more_people/accuracy=5.00e-01] model:[train/all/loss=2.90e-01, train/all/lr=1.00e-05]\n",
      "[20.0 epo]: RTE:[RTE_train/RTE_gold/loss=6.20e-01, RTE_valid/RTE_gold/accuracy=6.57e-01] RTE_slice:dash_semicolon:[RTE_train/RTE_slice:dash_semicolon/loss=6.19e-02, RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:more_people:[RTE_train/RTE_slice:more_people/loss=6.37e-02, RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] RTE_slice:BASE:[RTE_train/RTE_slice:BASE/loss=6.47e-02, RTE_valid/RTE_slice:BASE/accuracy=0] model:[train/all/loss=2.93e-01, train/all/lr=1.00e-05]\n",
      "[20.00 epo]: model:[train/all/lr=1.00e-05] RTE:[RTE_valid/RTE_gold/accuracy=6.57e-01] RTE_slice:dash_semicolon:[RTE_valid/RTE_slice:dash_semicolon/accuracy=6.03e-01] RTE_slice:more_people:[RTE_valid/RTE_slice:more_people/accuracy=5.83e-01] RTE_slice:BASE:[RTE_valid/RTE_slice:BASE/accuracy=0]\n",
      "Restoring best model from iteration 7.79 with score 0.697\n",
      "Finished training\n",
      "{'RTE/RTE_test/RTE_gold/accuracy': 0.0,\n",
      " 'RTE/RTE_train/RTE_gold/accuracy': 0.9325301204819277,\n",
      " 'RTE/RTE_valid/RTE_gold/accuracy': 0.6967509025270758,\n",
      " 'RTE_slice:BASE/RTE_test/RTE_slice:BASE/accuracy': 0,\n",
      " 'RTE_slice:BASE/RTE_train/RTE_slice:BASE/accuracy': 0,\n",
      " 'RTE_slice:BASE/RTE_valid/RTE_slice:BASE/accuracy': 0,\n",
      " 'RTE_slice:dash_semicolon/RTE_test/RTE_slice:dash_semicolon/accuracy': 0.0,\n",
      " 'RTE_slice:dash_semicolon/RTE_train/RTE_slice:dash_semicolon/accuracy': 0.9700897308075773,\n",
      " 'RTE_slice:dash_semicolon/RTE_valid/RTE_slice:dash_semicolon/accuracy': 0.6293103448275862,\n",
      " 'RTE_slice:more_people/RTE_test/RTE_slice:more_people/accuracy': 0.0,\n",
      " 'RTE_slice:more_people/RTE_train/RTE_slice:more_people/accuracy': 0.78125,\n",
      " 'RTE_slice:more_people/RTE_valid/RTE_slice:more_people/accuracy': 0.4166666666666667}\n",
      "Writing metrics to /dfs/scratch0/vschen/metal-mmtl/logs/2019_04_15/22_03_58/metrics.json\n",
      "Writing log to /dfs/scratch0/vschen/metal-mmtl/logs/2019_04_15/22_03_58/log.json\n",
      "Full model saved at /dfs/scratch0/vschen/metal-mmtl/logs/2019_04_15/22_03_58/model.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RTE/RTE_train/RTE_gold/accuracy': 0.9325301204819277,\n",
       " 'RTE_slice:dash_semicolon/RTE_train/RTE_slice:dash_semicolon/accuracy': 0.9700897308075773,\n",
       " 'RTE_slice:more_people/RTE_train/RTE_slice:more_people/accuracy': 0.78125,\n",
       " 'RTE_slice:BASE/RTE_train/RTE_slice:BASE/accuracy': 0,\n",
       " 'RTE/RTE_valid/RTE_gold/accuracy': 0.6967509025270758,\n",
       " 'RTE_slice:dash_semicolon/RTE_valid/RTE_slice:dash_semicolon/accuracy': 0.6293103448275862,\n",
       " 'RTE_slice:more_people/RTE_valid/RTE_slice:more_people/accuracy': 0.4166666666666667,\n",
       " 'RTE_slice:BASE/RTE_valid/RTE_slice:BASE/accuracy': 0,\n",
       " 'RTE/RTE_test/RTE_gold/accuracy': 0.0,\n",
       " 'RTE_slice:dash_semicolon/RTE_test/RTE_slice:dash_semicolon/accuracy': 0.0,\n",
       " 'RTE_slice:more_people/RTE_test/RTE_slice:more_people/accuracy': 0.0,\n",
       " 'RTE_slice:BASE/RTE_test/RTE_slice:BASE/accuracy': 0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## %%time\n",
    "trainer = MultitaskTrainer(seed=SEED)\n",
    "trainer.train_model(\n",
    "    slice_model,\n",
    "    payloads_slice,\n",
    "    task_metrics=[\n",
    "        \"RTE/RTE_train/RTE_gold/loss\", \n",
    "        \"RTE/RTE_train/RTE_slice:dash_semicolon/loss\", \n",
    "        \"RTE/RTE_train/RTE_slice:more_people/loss\",\n",
    "        \"RTE/RTE_valid/RTE_gold/accuracy\",\n",
    "        \"RTE/RTE_valid/RTE_slice:dash_semicolon/accuracy\", \n",
    "        \"RTE/RTE_valid/RTE_slice:more_people/accuracy\",\n",
    "    ],\n",
    "    checkpoint_metric=\"RTE/RTE_valid/RTE_gold/accuracy\",\n",
    "    checkpoint_metric_mode=\"max\",\n",
    "    checkoint_best=True,\n",
    "    writer=\"tensorboard\",\n",
    "    optimizer=\"adamax\",\n",
    "    lr=1e-5,\n",
    "#     l2=1e-3,\n",
    "    l2=1e-3,\n",
    "    log_every=0.1, \n",
    "    score_every=0.1,\n",
    "    n_epochs=20,\n",
    "    progress_bar=True,\n",
    "    checkpoint_best=True,\n",
    "    checkpoint_cleanup=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Did we improve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.49 s, sys: 208 ms, total: 1.7 s\n",
      "Wall time: 1.64 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RTE/RTE_valid/RTE_gold/accuracy': 0.6967509025270758,\n",
       " 'RTE_slice:dash_semicolon/RTE_valid/RTE_slice:dash_semicolon/accuracy': 0.6293103448275862,\n",
       " 'RTE_slice:more_people/RTE_valid/RTE_slice:more_people/accuracy': 0.4166666666666667,\n",
       " 'RTE_slice:BASE/RTE_valid/RTE_slice:BASE/accuracy': 0.6895306859205776}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "slice_model.score(payloads_slice[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RTE/RTE_valid/RTE_gold/accuracy': 0.6967509025270758,\n",
       " 'RTE/RTE_valid/RTE_slice:dash_semicolon/accuracy': 0.5862068965517241,\n",
       " 'RTE/RTE_valid/RTE_slice:more_people/accuracy': 0.75,\n",
       " 'RTE/RTE_valid/RTE_slice:BASE/accuracy': 0.6967509025270758}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice_model.score(eval_payload)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
