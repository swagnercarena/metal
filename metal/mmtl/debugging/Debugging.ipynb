{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tagger import Tagger\n",
    "tagger = Tagger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/dfs/scratch0/chami/metal/logs/2019_02_20/RTE_21_25_34/'\n",
    "task_name = 'RTE'\n",
    "split = 'dev'\n",
    "filepath = f'{task_name}_{split}_error_analysis.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find kwarg \"generate_uids\" in destination dict.\n",
      "Using random seed: 454012\n",
      "Loading RTE Dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c63cd595dc43298ec0355eec008530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=277), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "277it [00:10, 25.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataframe\n",
      "Saved dataframe to:  RTE_dev_error_analysis.tsv\n"
     ]
    }
   ],
   "source": [
    "# Load model and data\n",
    "model, dl = load_data_and_model(model_path,task_name,split)\n",
    "\n",
    "# Create DataFrame of Raw Data, Predictions, and Labels\n",
    "print('Creating dataframe')\n",
    "df_error = create_dataframe(task_name, model, dl)\n",
    "print('Created dataframe')\n",
    "\n",
    "# Save (and reload) DataFrame\n",
    "csv_path = '/'.join(model_path.split('/')[0:-1])\n",
    "save_dataframe(df_error, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error = load_dataframe(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>uid</th>\n",
       "      <th>pred</th>\n",
       "      <th>is_wrong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dana reeve , the widow of the actor christoph...</td>\n",
       "      <td>christopher reeve had an accident .</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>0</td>\n",
       "      <td>RTE/dev.tsv:2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>yet , we now are discovering that antibiotics...</td>\n",
       "      <td>bacteria is winning the war against antibioti...</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>1</td>\n",
       "      <td>RTE/dev.tsv:3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>cairo is now home to some 15 million people -...</td>\n",
       "      <td>15 million tonnes of rubbish are produced dai...</td>\n",
       "      <td>0.995439</td>\n",
       "      <td>0</td>\n",
       "      <td>RTE/dev.tsv:4</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>the ami ##sh community in pennsylvania , whic...</td>\n",
       "      <td>pennsylvania has the biggest ami ##sh communi...</td>\n",
       "      <td>0.005520</td>\n",
       "      <td>0</td>\n",
       "      <td>RTE/dev.tsv:5</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>security forces were on high alert after an e...</td>\n",
       "      <td>security forces were on high alert after a ca...</td>\n",
       "      <td>0.993684</td>\n",
       "      <td>1</td>\n",
       "      <td>RTE/dev.tsv:6</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          sentence1  \\\n",
       "0           0   dana reeve , the widow of the actor christoph...   \n",
       "1           1   yet , we now are discovering that antibiotics...   \n",
       "2           2   cairo is now home to some 15 million people -...   \n",
       "3           3   the ami ##sh community in pennsylvania , whic...   \n",
       "4           4   security forces were on high alert after an e...   \n",
       "\n",
       "                                           sentence2     score  label  \\\n",
       "0               christopher reeve had an accident .   0.003992      0   \n",
       "1   bacteria is winning the war against antibioti...  0.003810      1   \n",
       "2   15 million tonnes of rubbish are produced dai...  0.995439      0   \n",
       "3   pennsylvania has the biggest ami ##sh communi...  0.005520      0   \n",
       "4   security forces were on high alert after a ca...  0.993684      1   \n",
       "\n",
       "             uid  pred  is_wrong  \n",
       "0  RTE/dev.tsv:2     0     False  \n",
       "1  RTE/dev.tsv:3     0      True  \n",
       "2  RTE/dev.tsv:4     1      True  \n",
       "3  RTE/dev.tsv:5     0     False  \n",
       "4  RTE/dev.tsv:6     1     False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_error.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sandbox for Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0. Some basic statistics.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix and Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        y=1    y=2   \n",
      " l=1  *0.721  0.279  \n",
      " l=2   0.241 *0.759  \n",
      "\n",
      "Accuracy: 0.736\n",
      "Precision: 0.721\n",
      "Recall: 0.815\n",
      "F1: 0.765\n"
     ]
    }
   ],
   "source": [
    "from metal.analysis import confusion_matrix\n",
    "from metal.utils import convert_labels\n",
    "\n",
    "Y_gold = convert_labels(df_error['label'].values, \"onezero\", \"categorical\")\n",
    "Y_preds = convert_labels(df_error['pred'].values, \"onezero\", \"categorical\")\n",
    "Y_probs = np.vstack([df_error['score'].values, 1 - df_error['score'].values]).transpose()\n",
    "confusion_matrix(Y_gold, Y_preds, pretty_print=True, normalize=True)\n",
    "print()\n",
    "\n",
    "from metal.metrics import metric_score\n",
    "metric_list = ['accuracy','precision', 'recall', 'f1']\n",
    "\n",
    "for metric in metric_list:\n",
    "    score = metric_score(Y_gold, Y_preds, metric, probs=Y_probs)\n",
    "    print(f\"{metric.capitalize()}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Predictions and Predicted Probabilistic Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7364620938628159\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from metal.contrib.visualization.analysis import (\n",
    "        plot_predictions_histogram, \n",
    "        plot_probabilities_histogram,\n",
    "        plot_calibration_histogram\n",
    "    )\n",
    "plot_predictions_histogram(Y_preds, Y_gold, title=\"Label Distribution\")\n",
    "plot_calibration_histogram(Y_probs, Y_gold, title=\"Probablistic Label Distribution\", legend=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. We want to look at examples that are \"barely\" wrong and \"barely\" right since we have hope for boosts here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBARELY WRONG\u001b[0;0m\n",
      "No matches were found for the given criteria.\n",
      "\n",
      "\u001b[1mBARELY RIGHT\u001b[0;0m\n",
      "7 matches were found with the given criteria.\n",
      "\n",
      "UID:  RTE/dev.tsv:16\n",
      "sentence1: \t take consumer products giant pro ##cter and gamble . even with a $ 1 . 8 billion research and development budget , it still manages 500 active partnerships each year , many of them with small companies . \n",
      "sentence2: \t pro ##cter and gamble spends $ 1 . 8 billion for research and development . \n",
      "score: \t0.5972\n",
      "label: \t1\n",
      "\n",
      "UID:  RTE/dev.tsv:221\n",
      "sentence1: \t napkin ##s , invitations and plain old paper cost more than they did a month ago . \n",
      "sentence2: \t the cost of paper is rising . \n",
      "score: \t0.6086\n",
      "label: \t1\n",
      "\n",
      "UID:  RTE/dev.tsv:141\n",
      "sentence1: \t los angeles county probation officials say they are now studying how other counties recover juvenile detention costs , after admitting they mistakenly billed parents for days when youths were held in probation camps and halls . by law , california counties can bill parents and legal guardians for some daily costs of det ##ain ##ing youths , but only those whose parents can afford to pay . last year , more than 20 , 000 youths were admitted to probation camps and halls , and l . a . county billed parents a daily charge of $ 11 . 94 for camps , $ 23 . 63 for halls . \n",
      "sentence2: \t in los angeles county all parents have to pay the detention costs of their children . \n",
      "score: \t0.4265\n",
      "label: \t0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1mBARELY WRONG\\033[0;0m\")\n",
    "print_barely_wrong(df_error, thresh=0.2, n=3)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"\\033[1mBARELY RIGHT\\033[0;0m\")\n",
    "print_barely_right(df_error, thresh=0.2, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. We also want to look at examples we got completely wrong since that could point to a systematic bias in the data/model. It could also help us find examples in the dataset that are mislabeled by human annotators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mVERY WRONG\u001b[0;0m\n",
      "69 matches were found with the given criteria.\n",
      "\n",
      "UID:  RTE/dev.tsv:151\n",
      "sentence1: \t jerry reins ##dorf ( born february 25 1936 in brooklyn , new york ) is the owner of chicago white sox and the chicago bulls . recently , he helped the white sox win the 2005 world series and , in the process , collected his seventh championship ring overall ( the first six were all with the bulls in the 1990s ) , becoming the third owner in the history of north american sports to win a championship in two different sports . \n",
      "sentence2: \t jerry reins ##dorf has won 7 championships . \n",
      "score: \t0.0047\n",
      "label: \t1\n",
      "\n",
      "UID:  RTE/dev.tsv:212\n",
      "sentence1: \t for women earning 22 , 000 a year , the total pay accumulated after six months maternity leave would be just 5 , 300 in the uk and 5 , 850 in ireland . en ##ti ##tlement ##s in germany would also be relatively low , at 5 , 900 , along with those in france , spain and the netherlands , all at 6 , 750 . at the other end of the scale , pay received after six months leave in italy would be 9 , 150 while in denmark and norway it would be as much as 11 , 000 . \n",
      "sentence2: \t maternity leave varies in europe . \n",
      "score: \t0.0184\n",
      "label: \t1\n",
      "\n",
      "UID:  RTE/dev.tsv:140\n",
      "sentence1: \t note that sb ##b , cf ##f and ff ##s stand out for the main railway company , in german , french and italian . \n",
      "sentence2: \t the french railway company is called s ##nc ##f . \n",
      "score: \t0.9851\n",
      "label: \t0\n",
      "\n",
      "\u001b[1mVERY RIGHT\u001b[0;0m\n",
      "188 matches were found with the given criteria.\n",
      "\n",
      "UID:  RTE/dev.tsv:45\n",
      "sentence1: \t pi ##bu ##l song ##gram was the pro - japanese military dictator of thailand during world war 2 . \n",
      "sentence2: \t pi ##bu ##l was the dictator of thailand . \n",
      "score: \t0.9968\n",
      "label: \t1\n",
      "\n",
      "UID:  RTE/dev.tsv:271\n",
      "sentence1: \t in the history of art , prehistoric art is all art produced in pre ##lite ##rate cultures ( pre ##his ##tory ) , beginning somewhere in very late geological history . \n",
      "sentence2: \t prehistoric art discovered in south africa . \n",
      "score: \t0.0043\n",
      "label: \t0\n",
      "\n",
      "UID:  RTE/dev.tsv:81\n",
      "sentence1: \t the west has preferred to focus on endangered animals , rather than endangered humans . african elephants are hunted down and stripped of tu ##sk ##s and hidden by po ##ache ##rs . their numbers in africa slumped from 1 . 2 ##m to 600 , 000 in a decade until cites - the convention on international trade in endangered species - banned the trade in ivory . \n",
      "sentence2: \t african elephants are endangered by ivory po ##ache ##rs . \n",
      "score: \t0.9973\n",
      "label: \t1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1mVERY WRONG\\033[0;0m\")\n",
    "print_very_wrong(df_error, thresh=0.9, n=3)\n",
    "\n",
    "print(\"\\033[1mVERY RIGHT\\033[0;0m\")\n",
    "print_very_right(df_error, thresh=0.9, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. To find systematic errors, we can also look for correlations between certain features and the incorrectness a la Socratic**\n",
    "\n",
    "\n",
    "We can make this way more sophisticated by perhaps using embeddings instead of this simple [BoW featurization](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSYSTEMATIC EXAMPLES\u001b[0;0m\n",
      "award winning\n",
      "supreme court\n",
      "new government\n",
      "22 year old\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/scratch0/bradenjh/anaconda3/envs/metal/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patti nson\n",
      "\n",
      "8 matches were found with the given criteria.\n",
      "\n",
      "UID:  RTE/dev.tsv:77\n",
      "sentence1: \t a closely divided u . s . supreme court said on thursday its 2002 ruling that ju ##ries and not judges must impose a death sentence applies only to future cases , a decision that may affect more than 100 death row inmates . \n",
      "sentence2: \t the supreme court decided that only judges can impose the death sentence . \n",
      "score: \t0.9890\n",
      "label: \t0\n",
      "\n",
      "award winning\n",
      "supreme court said\n",
      "new government\n",
      "22 year old\n",
      "mark antony\n",
      "\n",
      "8 matches were found with the given criteria.\n",
      "\n",
      "UID:  RTE/dev.tsv:247\n",
      "sentence1: \t new york boasts the largest number of billionaire ##s , with 40 residing in the big apple . the world ' s youngest billionaire is 22 - year - old hind hari ##ri , daughter of assassinated former lebanese prime minister raf ##ik hari ##ri . \n",
      "sentence2: \t the number of billionaire ##s increases . \n",
      "score: \t0.9920\n",
      "label: \t0\n",
      "\n",
      "award winning\n",
      "new government\n",
      "supreme court said\n",
      "22 year old\n",
      "mark antony\n",
      "\n",
      "8 matches were found with the given criteria.\n",
      "\n",
      "UID:  RTE/dev.tsv:247\n",
      "sentence1: \t new york boasts the largest number of billionaire ##s , with 40 residing in the big apple . the world ' s youngest billionaire is 22 - year - old hind hari ##ri , daughter of assassinated former lebanese prime minister raf ##ik hari ##ri . \n",
      "sentence2: \t the number of billionaire ##s increases . \n",
      "score: \t0.9920\n",
      "label: \t0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1mSYSTEMATIC EXAMPLES\\033[0;0m\")\n",
    "for i in range(3):\n",
    "    print_systematic_wrong(df_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing Labeling Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Number Based LF**\n",
    "\n",
    "Our model tends to fail when there are numbers involved in the two sentences. We can look for the same number being repeated in both sentences as an LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_number(idx):\n",
    "    sentence1_nums = [int(s) for s in df_error['sentence1'][idx].split() if s.isdigit()]\n",
    "    sentence2_nums = [int(s) for s in df_error['sentence2'][idx].split() if s.isdigit()]\n",
    "    common_nums = len(set(sentence1_nums).intersection(set(sentence2_nums)))\n",
    "    \n",
    "    if (sentence1_nums == []) or (sentence2_nums == []):\n",
    "        return 0\n",
    "    \n",
    "    if common_nums > 0:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence1: \t about 33 . 5 million people live in this massive con ##ur ##bation . i would guess that 95 % of the 5 , 000 officially foreign - capital firms in japan are based in tokyo . \n",
      "sentence2: \t about 33 . 5 mi ##ili ##on people live in tokyo . \n",
      "score: \t0.0056\n",
      "label: \t1\n",
      "\n",
      "LF_label:  1\n",
      "\n",
      "\n",
      "sentence1: \t monica meadows , a 22 - year - old model from atlanta , was shot in the shoulder on a subway car in new york city . \n",
      "sentence2: \t monica meadows , 23 , was shot in shoulder while riding a subway car in new york city \n",
      "score: \t0.9879\n",
      "label: \t0\n",
      "\n",
      "LF_label:  0\n"
     ]
    }
   ],
   "source": [
    "print_row(df_error.iloc[70])\n",
    "print(\"LF_label: \", LF_number(70)-1)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print_row(df_error.iloc[254])\n",
    "print(\"LF_label: \", LF_number(254)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Edit Distance Based LF**\n",
    "\n",
    "Our model tends to vote entailment when one sentence is long and the other is short. We can focus on this slice and flip the labelt o vote no entailment even when the number of words is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshteinDistance(s1, s2):\n",
    "    if len(s1) > len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "\n",
    "    distances = range(len(s1) + 1)\n",
    "    for i2, c2 in enumerate(s2):\n",
    "        distances_ = [i2+1]\n",
    "        for i1, c1 in enumerate(s1):\n",
    "            if c1 == c2:\n",
    "                distances_.append(distances[i1])\n",
    "            else:\n",
    "                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
    "        distances = distances_\n",
    "    return distances[-1]\n",
    "\n",
    "from collections import Counter\n",
    "def common_words(s1,s2):\n",
    "    s1_set = set(Counter(s1.split()))\n",
    "    s2_set = set(Counter(s2.split()))\n",
    "    return len(s1_set.intersection(s2_set))/float(min(len(s1_set),len(s2_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_words(idx):\n",
    "    ratio = common_words(df_error['sentence1'][idx], df_error['sentence2'][idx])\n",
    "    if ratio < 0.3:\n",
    "        return 1\n",
    "    if (ratio <= 1.0) and (ratio > 0.4):\n",
    "        return 2\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence1: \t quebec woman and her mother accused of plotting to kill a four - year - old girl . \n",
      "sentence2: \t quebec woman murdered a four - year - old girl . \n",
      "score: \t0.0143\n",
      "label: \t0\n",
      "\n",
      "LF_label:  1\n",
      "\n",
      "\n",
      "sentence1: \t i asked myself how to understand the ' twilight ' s success . and i have come to the idea that when you really believe in something , sooner or later it will become real . so , i guess this is what happened with robert patti ##nson . last year he was just an unknown actor who ' s biggest role was in a pair of \" harry potter \" movies . now , not only that twilight is competing with ' harry potter ' , but robert patti ##nson is one of the most famous young actors who sucked $ 37 ##3 . 4 million from global box offices . so the movie about a vampire boy who falls in love with a normal girl , begun a real hysteria . and patti ##nson has a lot to do with it ! . \n",
      "sentence2: \t robert patti ##nson is a vampire . \n",
      "score: \t0.9955\n",
      "label: \t0\n",
      "\n",
      "LF_label:  1\n"
     ]
    }
   ],
   "source": [
    "print_row(df_error.iloc[150])\n",
    "print(\"LF_label: \", LF_words(150)-1)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print_row(df_error.iloc[95])\n",
    "print(\"LF_label: \", LF_words(95)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Labeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.zeros((np.shape(df_error)[0],2))\n",
    "for i in range(df_error.shape[0]):\n",
    "    L[i,0] = LF_number(i)\n",
    "    L[i,1] = LF_words(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeling Function Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1.0, 2.0]</td>\n",
       "      <td>0.158845</td>\n",
       "      <td>0.155235</td>\n",
       "      <td>0.025271</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1.0, 2.0]</td>\n",
       "      <td>0.949458</td>\n",
       "      <td>0.155235</td>\n",
       "      <td>0.025271</td>\n",
       "      <td>148</td>\n",
       "      <td>115</td>\n",
       "      <td>0.562738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Polarity  Coverage  Overlaps  Conflicts  Correct  Incorrect  Emp. Acc.\n",
       "0  [1.0, 2.0]  0.158845  0.155235   0.025271       22         22   0.500000\n",
       "1  [1.0, 2.0]  0.949458  0.155235   0.025271      148        115   0.562738"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metal.analysis import lf_summary\n",
    "from scipy.sparse import csr_matrix    \n",
    "\n",
    "L_sparse = csr_matrix(L)\n",
    "lf_summary(L_sparse,Y=df_error.label+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage Corrected by LF_num:  6.8493150684931505\n",
      "Percentage Corrected by LF_words:  31.506849315068493\n"
     ]
    }
   ],
   "source": [
    "incorrect = set(np.where(df_error.is_wrong == True)[0])\n",
    "LF1_set = set(np.where(L[:,0]-1. == df_error.label)[0])\n",
    "LF2_set = set(np.where(L[:,1]-1. == df_error.label)[0])\n",
    "\n",
    "print(\"Percentage Corrected by LF_num: \", 100.*len(LF1_set.intersection(incorrect))/float(len(incorrect)))\n",
    "print(\"Percentage Corrected by LF_words: \", 100.*len(LF2_set.intersection(incorrect))/float(len(incorrect)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Model for Task A to Predict on Train Set for Task B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with QNLI and RTE since those are both about `entailment` and `not_entailment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model config (needs to be the same as parameters used for training)\n",
    "bert_model = \"bert-base-uncased\"\n",
    "max_len = 256\n",
    "bert_output_dim = 768\n",
    "max_datapoints = -1\n",
    "dl_kwargs = {\"batch_size\": 32, \"shuffle\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02/19/19\n",
    "model_paths = {\n",
    "    'MNLI_SAN': '/dfs/scratch1/senwu/mmtl/logs/checkpoints/17-2-2019/MNLI_SAN_02_27_41/',\n",
    "    'QNLI': '/dfs/scratch0/mccreery/mmtl/logs/2019_02_19/QNLI_09_56_46/',\n",
    "    'STSB': '/dfs/scratch0/mccreery/mmtl/logs/2019_02_19/STSB_09_46_46/',\n",
    "    'SST2': '/dfs/scratch0/mccreery/mmtl/logs/2019_02_19/SST2_06_01_35/',\n",
    "    'COLA': '/dfs/scratch0/mccreery/mmtl/logs/2019_02_19/COLA_05_49_39/',\n",
    "    'RTE':'/dfs/scratch0/mccreery/mmtl/logs/2019_02_19/RTE_06_32_37/',\n",
    "    'WNLI': '/dfs/scratch0/mccreery/mmtl/logs/2019_02_19/WNLI_06_38_32/',\n",
    "    'QQP': '/dfs/scratch0/mccreery/mmtl/logs/2019_02_19/QQP_06_47_48/',\n",
    "    'MRPC':'/dfs/scratch0/mccreery/mmtl/logs/2019_02_19/MRPC_09_40_25/'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_task_name = 'QNLI'\n",
    "# target_task_name = 'RTE'\n",
    "\n",
    "# #create source task\n",
    "# source_task = create_tasks(\n",
    "#     task_names=[source_task_name],\n",
    "#     bert_model=bert_model,\n",
    "#     max_len=max_len,\n",
    "#     dl_kwargs=dl_kwargs,\n",
    "#     splits=['test'],\n",
    "#     max_datapoints=max_datapoints,\n",
    "# )[0]\n",
    "\n",
    "# # load source model weights \n",
    "# source_model_path = os.path.join(model_paths[source_task_name], 'best_model.pth')\n",
    "# source_model = MetalModel([source_task], verbose=False, device=0)\n",
    "# source_model.load_weights(source_model_path)\n",
    "# source_model.eval()\n",
    "    \n",
    "    \n",
    "# #create target task\n",
    "# target_task = create_tasks(\n",
    "#     task_names=[target_task_name],\n",
    "#     bert_model=bert_model,\n",
    "#     max_len=max_len,\n",
    "#     dl_kwargs=dl_kwargs,\n",
    "#     splits=['train'],\n",
    "#     max_datapoints=max_datapoints,\n",
    "# )[0]\n",
    "\n",
    "# # predict on target task train set\n",
    "# target_task.name = source_task_name #HACK FOR LINE 225 in METAL_MODEL.PY\n",
    "# Y, Y_probs, Y_preds = source_model._predict_probs(\n",
    "#     target_task, split='train', return_preds=True)\n",
    "\n",
    "# # true labels for target task train set\n",
    "# Y_true = []\n",
    "# for x, y in tqdm(list(target_task.data_loaders['train'])):\n",
    "#     Y_true += list(y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confident_idx = list(np.where(np.abs(Y_probs[:,0]-0.5) >= 0.4)[0])\n",
    "# Y_true = np.array(Y_true)\n",
    "# print (f'Accuracy of {source_task_name} model on {target_task_name}: {np.mean(Y_preds[confident_idx] == Y_true[confident_idx])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (metal)",
   "language": "python",
   "name": "metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
